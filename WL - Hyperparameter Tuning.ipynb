{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21062639",
   "metadata": {},
   "source": [
    "# WL Kernel Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11e64e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45973340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports all the libraries needed \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from grakel.kernels import ShortestPath\n",
    "from grakel import Graph\n",
    "import scipy.io\n",
    "import os\n",
    "import glob\n",
    "from grakel import GraphKernel\n",
    "from grakel.kernels import ShortestPathAttr, SubgraphMatching, PropagationAttr\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import cv2\n",
    "import pickle\n",
    "from grakel.kernels import WeisfeilerLehman, VertexHistogram, NeighborhoodHash, WeisfeilerLehmanOptimalAssignment\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d852d",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a498cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image:np.array)->np.array:\n",
    "    \"\"\" Downsample every image in order to speed up calculations.\n",
    "        We choose every second pixel -> Reduce size in half. \n",
    "    :param image: The original image of type `np.array`.\n",
    "    :return: Return the same image downsampled half the size. \n",
    "    \"\"\"\n",
    "    return image[0::2, 0::2]\n",
    "\n",
    "\n",
    "def load_image(path: str)->np.array:\n",
    "    \"\"\"\n",
    "     Load the image from the specified path. \n",
    "     Pixel intensities take values in the range [0,255] and are represented using all 3 channels (RGB). \n",
    "     redChannel   = image_imported[:,:,0] - Red channel\n",
    "     greenChannel = image_imported[:,:,1] - Green channel\n",
    "     blueChannel  = image_imported[:,:,2] - Blue channel\n",
    "    \n",
    "    :param path: The path of the image of type `str`.\n",
    "    :return image: The image to return stored as `np.array`.\n",
    "    \"\"\"\n",
    "    image_imported = Image.open(path)\n",
    "    image = np.array(image_imported)\n",
    "    image = downsample_image(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_ground_truth_images()->dict:\n",
    "    \"\"\" Create a dictionary with groundtruth segmentations for each image in the training set.\n",
    "    \n",
    "    :return groundtruth: Dictionary of the form key:[segmentation,number of segments,chosen_truth]. For each image\n",
    "    we might have more than 1 ground truth segmentations so we will return the segmentation with the MINIMUM \n",
    "    number of segments. Key is going to be the number of the image. \n",
    "    \"\"\"\n",
    "    folder_path = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/groundTruth/train\"  \n",
    "    # Construct the pattern to match image files\n",
    "    image_pattern = os.path.join(folder_path, '*.mat')  \n",
    "    # Use glob to find all matching image file paths\n",
    "    image_paths = glob.glob(image_pattern)\n",
    "    train_paths = []\n",
    "    groundtruth = {}\n",
    "    # Replace \\ with /\n",
    "    for path in image_paths:\n",
    "        updated_string = path.rsplit(\"\\\\\", 1)\n",
    "        updated_string = \"/\".join(updated_string)\n",
    "        train_paths.append(updated_string)\n",
    "\n",
    "    for path in image_paths:\n",
    "        mat_path = path\n",
    "        # Get the file name from the path\n",
    "        file_name = os.path.basename(path)\n",
    "        # Remove the file extension\n",
    "        file_name = os.path.splitext(file_name)[0]\n",
    "        # Extract the number\n",
    "        image_number = file_name.split(\"\\\\\")[-1]\n",
    "\n",
    "        mat_contents = scipy.io.loadmat(mat_path)\n",
    "        num_of_groundtruths = mat_contents['groundTruth'][0].shape[0]\n",
    "        num_regions = []\n",
    "        for i in range(0,num_of_groundtruths):\n",
    "            # Find the number of distinct elements\n",
    "            num_distinct_elements = len(np.unique(mat_contents['groundTruth'][0][i][0][0][0]))\n",
    "            num_regions.append(num_distinct_elements)\n",
    "        max_index = num_regions.index(min(num_regions))  # TODO: Modify this accordingly\n",
    "        selected_truth = mat_contents['groundTruth'][0][max_index][0][0][0]\n",
    "        # Downsample true segmentation \n",
    "        selected_truth = downsample_image(selected_truth)\n",
    "        groundtruth[image_number] = [selected_truth,len(np.unique(selected_truth)), max_index]\n",
    "    return groundtruth\n",
    "    \n",
    "\n",
    "def superpixel_SLIC(image: np.array, n_segments:int, compactness:int) ->np.array:\n",
    "    \"\"\"\n",
    "    Create superpixels using SLIC algorithm.\n",
    "    \n",
    "    \n",
    "    :param image: Image of type 'np.array' having all 3 channels (RGB format)\n",
    "    :param n_segments: Approximate number of superpixels of type `int`.\n",
    "    :param compactness: Defines the tradeoff between space and color proximity of type `int`. \n",
    "     High m  -> more square superpixels.\n",
    "     Small m -> arbitary shapes for superpixels but more sensitive to boundries.\n",
    "    :return superpixels: The superpixel regions of type 'np.array'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use lab color format\n",
    "    lab = rgb2lab(image)\n",
    "\n",
    "    # Use SLIC algorithm for superpixel segmentation\n",
    "    superpixels = slic(lab, n_segments=n_segments, compactness=compactness, start_label=1)\n",
    "    return superpixels\n",
    "\n",
    "\n",
    "\n",
    "def Euclidean_distance(vector_a, vector_b):\n",
    "    \"\"\" Calculate Euclidean distance between co-ordinates-vectors of 2 pixels. \n",
    "    \n",
    "    :param vector_a: Co-ordinates of first node of type `list`.\n",
    "    :param vector_b: Co-ordinates of second node of type `list`.\n",
    "    :return result: Return the Euclidean distance of co-ordinates of type `int`. \n",
    "    \"\"\"\n",
    "    result = np.sqrt((vector_a[0]-vector_b[0])**2 + (vector_a[1]-vector_b[1])**2)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def get_image_number(path:str)->str:\n",
    "    \"\"\" Extract image number from path. \n",
    "    :param path: The path of the image of type `str`.\n",
    "    :return image_number: Return the image number of type `str`.\n",
    "    \"\"\"\n",
    "    # Get the file name from the path\n",
    "    file_name = os.path.basename(path)\n",
    "    # Remove the file extension\n",
    "    file_name = os.path.splitext(file_name)[0]\n",
    "    # Extract the number\n",
    "    image_number = file_name.split(\"\\\\\")[-1]\n",
    "    return image_number\n",
    "    \n",
    "\n",
    "def create_graphs(image: np.array, superpixels: np.array)->list:\n",
    "    \"\"\"\n",
    "    Create a list of Graphs where each graph corresponds to a superpixel. Every node in each graph has\n",
    "    as attributes the RGB values. Each node is connected with at-most 8 neighboors. \n",
    "    \n",
    "    :param image: Image of type 'np.array' having all 3 channels (RGB format).\n",
    "    :param superpixels: The superpixel regions of type 'np.array'.\n",
    "    :return image_graphs: A `list` with graphs for each superpixel. Each graph is an instance of the class\n",
    "    `Graph` within the Grakel library.  \n",
    "    \"\"\"\n",
    "    num_of_superpixels = len(np.unique(superpixels)) # The number of superpixels-graphs \n",
    "    image_graphs = []\n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixels == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        adj_matrix = np.zeros((len(indices), len(indices)))  # Adjacency matrix\n",
    "        node_attributes = {}  # Dictionary with attributes for each vertex.\n",
    "        examined_vertices = []\n",
    "        vertex_index = 0\n",
    "        for vector in indices:\n",
    "            x_coordinate       = vector[0]\n",
    "            y_coordinate       = vector[1]\n",
    "            redChannel_value   = image[x_coordinate,y_coordinate,0] # Red channel pixel value \n",
    "            greenChannel_value = image[x_coordinate,y_coordinate,1] # Green channel pixel value\n",
    "            blueChannel_value  = image[x_coordinate,y_coordinate,2] # Blue channel pixel value\n",
    "            # Update dictionary with attributes for each vertex\n",
    "            node_attributes[vertex_index] = [redChannel_value, greenChannel_value, blueChannel_value]\n",
    "            if examined_vertices == []:  # This is the first vertex to be added\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "            else:\n",
    "                # Update adjacency matrix\n",
    "                for index, existing_vertex in enumerate(examined_vertices):\n",
    "                    if Euclidean_distance(existing_vertex, vector) < 1.45:  # Use a 8-neighbourhood\n",
    "                        adj_matrix[index, vertex_index] = 1\n",
    "                        adj_matrix[vertex_index, index] = 1\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "        G = Graph(adj_matrix, node_labels=node_attributes)\n",
    "        image_graphs.append(G)\n",
    "    return image_graphs\n",
    "\n",
    "\n",
    "def create_graphs_grayscale(image: np.array, superpixels: np.array)->list:\n",
    "    \"\"\"\n",
    "    Create a list of Graphs where each graph corresponds to a superpixel. Every node in each graph has\n",
    "    as label the grayscale pixel intensity value in the range [0,255]. Each node is connected with at-most 8 neighboors. \n",
    "    \n",
    "    :param image: Image of type 'np.array' having all 3 channels (RGB format).\n",
    "    :param superpixels: The superpixel regions of type 'np.array'.\n",
    "    :return image_graphs: A `list` with graphs for each superpixel. Each graph is an instance of the class\n",
    "    `Graph` within the Grakel library. \n",
    "    \"\"\"\n",
    "    num_of_superpixels = len(np.unique(superpixels)) # The number of superpixels-graphs \n",
    "    image_graphs = []\n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixels == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        adj_matrix = np.zeros((len(indices), len(indices)))  # Adjacency matrix\n",
    "        node_labels = {}  # Dictionary with labels for each vertex.\n",
    "        examined_vertices = []\n",
    "        vertex_index = 0\n",
    "        for vector in indices:\n",
    "            x_coordinate       = vector[0]\n",
    "            y_coordinate       = vector[1]\n",
    "            image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            pixel_intensity    = image_gray[x_coordinate,y_coordinate]\n",
    "            # Update dictionary with attributes for each vertex\n",
    "            node_labels[vertex_index] = pixel_intensity\n",
    "            if examined_vertices == []:  # This is the first vertex to be added\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "            else:\n",
    "                # Update adjacency matrix\n",
    "                for index, existing_vertex in enumerate(examined_vertices):\n",
    "                    if Euclidean_distance(existing_vertex, vector) < 1.45:  # Use a 8-neighbourhood\n",
    "                        adj_matrix[index, vertex_index] = 1\n",
    "                        adj_matrix[vertex_index, index] = 1\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "        G = Graph(adj_matrix, node_labels=node_labels)\n",
    "        image_graphs.append(G)\n",
    "    return image_graphs\n",
    "\n",
    "\n",
    "def convert_seg_to_boundaries(seg:np.array)->np.array:\n",
    "    \"\"\" Convert segmentation which uses a different number for each segment into boundries which is \n",
    "        a numpy array that contains 1 for boundry pixels. \n",
    "    \n",
    "    :param seg: The segmentation in region format of type 'np.array'.\n",
    "    :return result: The segmentation in boundry format of type `np.array`.\n",
    "    \"\"\"\n",
    "    seg_padded = np.pad(seg, ((1, 0), (1, 0)), mode='constant', constant_values=seg[-1, -1])\n",
    "    \n",
    "    dx = cv2.Sobel(seg_padded, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    dy = cv2.Sobel(seg_padded, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    boundaries = np.abs(dx) + np.abs(dy)\n",
    "    \n",
    "    boundaries = boundaries[:-1, :-1]\n",
    "    boundaries = cv2.threshold(boundaries, 0, 1, cv2.THRESH_BINARY)[1]\n",
    "    result = boundaries.astype(np.uint8)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def evaluate(Predictions: np.array, Human: np.array)->float:\n",
    "    \"\"\" Calculate the F1-score between the predicted boundries and the ground truth. \n",
    "    \n",
    "    :param Predictions: The predicted boundries of type `np.array`.\n",
    "    :param Human: The human labelled boundries of type `np.array`.\n",
    "    :return f1score: F1 score which takes values between 0 and 1. Value is rounded to 4 decimal points and the \n",
    "    closer the value to 1 the better.\n",
    "    \"\"\"\n",
    "    \n",
    "    TP = Predictions * Human\n",
    "    numFP = 0\n",
    "    numFN = 0\n",
    "    nrow, ncol = Predictions.shape\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            if (Predictions[i,j] == 1) & (Human[i,j]==0):\n",
    "                numFP = numFP + 1\n",
    "            if (Predictions[i,j] == 0) & (Human[i,j]==1): \n",
    "                numFN = numFN + 1\n",
    "    numTP = np.sum(TP)\n",
    "    f1score = 2 * numTP / (2 * numTP + numFP + numFN)\n",
    "\n",
    "    return round(f1score, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7125e",
   "metadata": {},
   "source": [
    "# Data Transformation - Convert Images to Graphs with Node Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Create a list with all the paths for the images in the training set #\n",
    "#######################################################################\n",
    "\n",
    "folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/train\"  \n",
    "# Construct the pattern to match image files\n",
    "image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "# Use glob to find all matching image file paths\n",
    "image_paths = glob.glob(image_pattern)\n",
    "train_paths = []\n",
    "\n",
    "# Print the paths for each image\n",
    "for path in image_paths:\n",
    "    updated_string = path.rsplit(\"\\\\\", 1)\n",
    "    updated_string = \"/\".join(updated_string)\n",
    "    train_paths.append(updated_string)\n",
    "    \n",
    "###############################################################################\n",
    "# Create a list of lists containing graphs for each image in the training set #\n",
    "###############################################################################\n",
    "\n",
    "images_to_graphs = []\n",
    "original_images = []\n",
    "superpixel_segmentations = []\n",
    "for path in train_paths:  \n",
    "    current_image = load_image(path)\n",
    "    original_images.append(current_image)\n",
    "    segments = superpixel_SLIC(current_image, 800, 10)\n",
    "    superpixel_segmentations.append(segments)\n",
    "    graphs = create_graphs_grayscale(current_image, segments)\n",
    "    images_to_graphs.append(graphs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a5263",
   "metadata": {},
   "source": [
    "# Plot Superpixels for first 5 Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cecd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 2, 2*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 2, 2*i+2)\n",
    "    plt.imshow(mark_boundaries(image, superpixel_segmentations[i]))\n",
    "    plt.axis('off')\n",
    "    plt.title('Superpixels', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d495231",
   "metadata": {},
   "source": [
    "# Load Ground Truth Segmentations of Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d739064",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                      Load Ground Truth Segmentations                        #\n",
    "###############################################################################\n",
    "# Get dictionary of ground-truth-segmentations\n",
    "ground_truth_segmentations = load_ground_truth_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d40f7",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning - WL with Vertex Histogram as Base Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ea600",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [2,3,4,5,6,7]  # Maximum number of iterations. \n",
    "F1_max = 0\n",
    "t_max = 0\n",
    "F_scores = []\n",
    "itteration = 0\n",
    "\n",
    "for j in t:\n",
    "    itteration = itteration + 1\n",
    "    print('Itteration: ', itteration)\n",
    "    print('Parameter: ', j)\n",
    "    print('Calculate Kernel Matrices')\n",
    "    gk = WeisfeilerLehman(normalize=False, n_iter=j)\n",
    "    Kernel_matrix = []\n",
    "    for image in images_to_graphs:\n",
    "        current_matrix = gk.fit_transform(image)\n",
    "        # Convert kernel matrix to dissimilarity matrix \n",
    "        current_matrix =  np.max(current_matrix) - current_matrix\n",
    "        Kernel_matrix.append(current_matrix)\n",
    "    #######################################################################\n",
    "    # Perform Clustering Using Kernel Matrices and Hierrarchical Clustering\n",
    "    # For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "    # Get the image number which will be used as key for the groundtruth\n",
    "    predicted_clusters = []\n",
    "    for i in range(0,len(Kernel_matrix)):\n",
    "        Image_number = get_image_number(train_paths[i])\n",
    "        k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "        # Perform hierarchical clustering with group average\n",
    "        print('Perform Clustering')\n",
    "        print()\n",
    "        clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "        labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "        predicted_clusters.append(labels)\n",
    "    #########################################################################\n",
    "    # We need to convert the cluster labels to pixel labels\n",
    "    # Each graph in images_to_graphs is assigned a cluster. However each graph is also connected to \n",
    "    # several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "    image_segmentations = []\n",
    "    for i in range(0,len(Kernel_matrix)):\n",
    "        current_image = load_image(train_paths[i])\n",
    "        n_row, n_col, _ = current_image.shape\n",
    "        image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "        num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "        for graph_num in range(1,num_of_superpixels+1):\n",
    "            indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "            for pixel in indices:\n",
    "                x = pixel[0]\n",
    "                y = pixel[1]\n",
    "                image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "\n",
    "        image_segmentations.append(image_segmentation)\n",
    "    ##########################################################################\n",
    "    # For the evaluation of the segmentation performance F1-score is going to be used.\n",
    "    # Get the image number which will be used as key for the groundtruth\n",
    "    F1_scores = []\n",
    "    for i in range(0,len(Kernel_matrix)):\n",
    "        Image_number = get_image_number(train_paths[i])\n",
    "        ground_truth               = ground_truth_segmentations[Image_number]\n",
    "        # Get chosen ground truth-segmentation\n",
    "        ground_truth               = ground_truth[0]\n",
    "\n",
    "        # Convert segmentations into boundry formats\n",
    "        ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "        image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "        # Calculate performance measures \n",
    "        F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "        F1_scores.append(F_score)\n",
    "    F_scores.append(F1_scores)\n",
    "    avg_F = sum(F1_scores) / len(F1_scores)\n",
    "    if avg_F > F1_max:\n",
    "        F1_max = avg_F\n",
    "        t_max = j\n",
    "\n",
    "            \n",
    "print('The chosen parameter for WL kernel is: ')\n",
    "print('t =', t_max)\n",
    "print('Avg F1 Score =', F1_max)\n",
    "\n",
    "# Write the parameters in a file\n",
    "parameters = [t_max, F1_max]\n",
    "\n",
    "# Specify the file path and name\n",
    "csv_file = 'WL_parameters.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in parameters:\n",
    "        writer.writerow([item])\n",
    "\n",
    "        \n",
    "# Store detailed results\n",
    "\n",
    "# Specify the file path and name\n",
    "csv_file = 'WL_parameters_detailed.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "# Save the list as a pickle file\n",
    "with open('WL_parameters_detailed.pkl', 'wb') as file:\n",
    "    pickle.dump(F_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43386afd",
   "metadata": {},
   "source": [
    "## Create Plot with Results for Different Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file with the results\n",
    "with open('WL_parameters_detailed.pkl', 'rb') as file:\n",
    "    tuning_results = pickle.load(file)\n",
    "    \n",
    "# Create a list which stores the parameters of each trial\n",
    "labels = []\n",
    "for j in t:\n",
    "    labels.append('n_itter= '+str(j))\n",
    "\n",
    "# Increase figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style='ticks', context='paper')\n",
    "# Plot the results\n",
    "ax = sns.boxplot(data=tuning_results)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "plt.title(\"F1 scores on training set using WL\")\n",
    "\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Parameters')\n",
    "plt.ylabel('F1 score')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33272f9b",
   "metadata": {},
   "source": [
    "# Plot Segmentations for first 5 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12339c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 2, 2*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 2, 2*i+2)\n",
    "    plt.imshow(image_segmentations[i])\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e43b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
