{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21062639",
   "metadata": {},
   "source": [
    "# Image Segmentation using graph kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11e64e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45973340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports all the libraries needed \n",
    "from skimage import color\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from skimage import data, segmentation, color\n",
    "from skimage import graph\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from grakel.kernels import ShortestPath\n",
    "from grakel import Graph\n",
    "import scipy.io\n",
    "import os\n",
    "import glob\n",
    "from grakel import GraphKernel\n",
    "from grakel.kernels import ShortestPathAttr, SubgraphMatching, PropagationAttr\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import cv2\n",
    "import pickle\n",
    "from grakel.kernels import WeisfeilerLehman, VertexHistogram, NeighborhoodHash, WeisfeilerLehmanOptimalAssignment, EdgeHistogram\n",
    "import csv\n",
    "import statistics\n",
    "from skimage import io, color\n",
    "import math\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Number of Images to process from validation set\n",
    "num_images = 100\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d852d",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a498cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image:np.array)->np.array:\n",
    "    \"\"\" Downsample every image in order to speed up calculations.\n",
    "        We choose every second pixel -> Reduce size in half. \n",
    "    :param image: The original image of type `np.array`.\n",
    "    :return: Return the same image downsampled half the size. \n",
    "    \"\"\"\n",
    "    return image[0::2, 0::2]\n",
    "\n",
    "\n",
    "def load_image(path: str)->np.array:\n",
    "    \"\"\"\n",
    "     Load the image from the specified path. \n",
    "     Pixel intensities take values in the range [0,255] and are represented using all 3 channels (RGB). \n",
    "     redChannel   = image_imported[:,:,0] - Red channel\n",
    "     greenChannel = image_imported[:,:,1] - Green channel\n",
    "     blueChannel  = image_imported[:,:,2] - Blue channel\n",
    "    \n",
    "    :param path: The path of the image of type `str`.\n",
    "    :image_imported : The image stored as `np.array`. \n",
    "\n",
    "    \"\"\"\n",
    "    image_imported = Image.open(path)\n",
    "    image = np.array(image_imported)\n",
    "    image = downsample_image(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_ground_truth_images()-> dict:\n",
    "    \"\"\" Create a dictionary with groundtruth segmentations for each image in the training set.\n",
    "    \n",
    "    :return groundtruth: Dictionary of the form key:[segmentation,number of segments,chosen_truth]. For each image\n",
    "    we might have more than 1 ground truth segmentations so we will return the segmentation with the most \n",
    "    number of segments. Key is going to be the number of the image. \n",
    "    \"\"\"\n",
    "    folder_path = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/groundTruth/val\"  \n",
    "    # Construct the pattern to match image files\n",
    "    image_pattern = os.path.join(folder_path, '*.mat')  \n",
    "    # Use glob to find all matching image file paths\n",
    "    image_paths = glob.glob(image_pattern)\n",
    "    train_paths = []\n",
    "    groundtruth = {}\n",
    "    # Replace \\ with /\n",
    "    for path in image_paths:\n",
    "        updated_string = path.rsplit(\"\\\\\", 1)\n",
    "        updated_string = \"/\".join(updated_string)\n",
    "        train_paths.append(updated_string)\n",
    "\n",
    "    for path in image_paths:\n",
    "        mat_path = path\n",
    "        # Get the file name from the path\n",
    "        file_name = os.path.basename(path)\n",
    "        # Remove the file extension\n",
    "        file_name = os.path.splitext(file_name)[0]\n",
    "        # Extract the number\n",
    "        image_number = file_name.split(\"\\\\\")[-1]\n",
    "\n",
    "        mat_contents = scipy.io.loadmat(mat_path)\n",
    "        num_of_groundtruths = mat_contents['groundTruth'][0].shape[0]\n",
    "        num_regions = []\n",
    "        for i in range(0,num_of_groundtruths):\n",
    "            # Find the number of distinct elements\n",
    "            num_distinct_elements = len(np.unique(mat_contents['groundTruth'][0][i][0][0][0]))\n",
    "            num_regions.append(num_distinct_elements)\n",
    "        max_index = num_regions.index(min(num_regions))  # TODO: Modify this accordingly\n",
    "        selected_truth = mat_contents['groundTruth'][0][max_index][0][0][0]\n",
    "        # Downsample true segmentation \n",
    "        selected_truth = downsample_image(selected_truth)\n",
    "        groundtruth[image_number] = [selected_truth,len(np.unique(selected_truth)), max_index]\n",
    "    return groundtruth\n",
    "    \n",
    "\n",
    "def superpixel_SLIC(image: np.array, n_segments:int, compactness:int) ->np.array:\n",
    "    \"\"\"\n",
    "    Create superpixels using SLIC algorithm.\n",
    "    \n",
    "    \n",
    "    :param image: Image of type 'np.array' having all 3 channels (RGB format)\n",
    "    :param n_segments: Approximate number of superpixels of type `int`.\n",
    "    :param compactness: Defines the tradeoff between space and color proximity of type `int`. \n",
    "    High m  -> more square superpixels.\n",
    "    Small m -> arbitary shapes for superpixels but more sensitive to boundries.\n",
    "    :return superpixels: The superpixel regions of type 'np.array'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use lab color format\n",
    "    lab = rgb2lab(image)\n",
    "\n",
    "    # Use SLIC algorithm for superpixel segmentation\n",
    "    superpixels = slic(lab, n_segments=n_segments, compactness=compactness, start_label=1)\n",
    "    return superpixels\n",
    "\n",
    "def Euclidean_distance(vector_a:list, vector_b:list)->float:\n",
    "    \"\"\" Calculate Euclidean distance between co-ordinates-vectors of 2 pixels. \n",
    "    \n",
    "    :param vector_a: Co-ordinates of first node of type `list`.\n",
    "    :param vector_b: Co-ordinates of second node of type `list`.\n",
    "    :return result: Return the Euclidean distance of co-ordinates of type `int`. \n",
    "    \"\"\"\n",
    "    result = np.sqrt((vector_a[0]-vector_b[0])**2 + (vector_a[1]-vector_b[1])**2)\n",
    "    return result\n",
    "\n",
    "def rgb_to_grayscale(rgb):\n",
    "    \"\"\" Compute grayscale value from RGB values. \n",
    "    :param rgb: The RGB value of type `list`.\n",
    "    :return grayscale: The pixel intensity grayscale value in the range [0,255] of type `int`.\n",
    "    \"\"\"\n",
    "    grayscale = int(0.2989 * rgb[0] + 0.5870 * rgb[1] + 0.1140 * rgb[2])\n",
    "    return grayscale\n",
    "\n",
    "\n",
    "def edge_labels_calc(vector_a:list, vector_b:list)->str:\n",
    "    \"\"\" Calculate edge labels by concatinating pixel intensity values. \n",
    "    \n",
    "    :param vector_a: RGB values of first node of type `list`.\n",
    "    :param vector_b: RGB values of second node of type `list`.\n",
    "    :return: String with edge label.     \n",
    "    \"\"\"\n",
    "    # Concatinate Pixel Intensity Values. \n",
    "    A = rgb_to_grayscale(vector_a)\n",
    "    B = rgb_to_grayscale(vector_b)\n",
    "    return str(A)+str(B)\n",
    "\n",
    "\n",
    "def get_image_number(path: str)-> str:\n",
    "    \"\"\" Extract image number from path. \n",
    "    :param path: The path of the image of type `str`.\n",
    "    :return image_number: Return the image number of type `str`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the file name from the path\n",
    "    file_name = os.path.basename(path)\n",
    "    # Remove the file extension\n",
    "    file_name = os.path.splitext(file_name)[0]\n",
    "    # Extract the number\n",
    "    image_number = file_name.split(\"\\\\\")[-1]\n",
    "    return image_number\n",
    "\n",
    "\n",
    "def create_graphs(image: np.array, superpixels: np.array)->list:\n",
    "    \"\"\"\n",
    "    Create a list of Graphs where each graph corresponds to a superpixel. Every node in each graph has\n",
    "    as attributes the RGB values. Each node is connected with at-most 8 neighboors. \n",
    "    \n",
    "    :param image: Image of type 'np.array' having all 3 channels (RGB format).\n",
    "    :param superpixels: The superpixel regions of type 'np.array'.\n",
    "    :return image_graphs: A `list` with graphs for each superpixel. Each graph is an instance of the class\n",
    "    `Graph` within the Grakel library.  \n",
    "    \"\"\"\n",
    "    num_of_superpixels = len(np.unique(superpixels)) # The number of superpixels-graphs \n",
    "    image_graphs = []\n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixels == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        adj_matrix = np.zeros((len(indices), len(indices)))  # Adjacency matrix\n",
    "        node_attributes = {}  # Dictionary with attributes for each vertex.\n",
    "        examined_vertices = []\n",
    "        vertex_index = 0\n",
    "        for vector in indices:\n",
    "            x_coordinate       = vector[0]\n",
    "            y_coordinate       = vector[1]\n",
    "            redChannel_value   = image[x_coordinate,y_coordinate,0] # Red channel pixel value \n",
    "            greenChannel_value = image[x_coordinate,y_coordinate,1] # Green channel pixel value\n",
    "            blueChannel_value  = image[x_coordinate,y_coordinate,2] # Blue channel pixel value\n",
    "                        \n",
    "            # Update dictionary with attributes for each vertex\n",
    "            node_attributes[vertex_index] = [redChannel_value, greenChannel_value, blueChannel_value]\n",
    "            if examined_vertices == []:  # This is the first vertex to be added\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "            else:\n",
    "                # Update adjacency matrix\n",
    "                for index, existing_vertex in enumerate(examined_vertices):\n",
    "                    if Euclidean_distance(existing_vertex, vector) < 1.45:  # Use a 8-neighbourhood\n",
    "                        adj_matrix[index, vertex_index] = 1\n",
    "                        adj_matrix[vertex_index, index] = 1\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "        G = Graph(adj_matrix, node_labels=node_attributes)\n",
    "        image_graphs.append(G)\n",
    "    return image_graphs\n",
    "\n",
    "\n",
    "def create_graphs_grayscale(image: np.array, superpixels: np.array)->list:\n",
    "    \"\"\"\n",
    "    Create a list of Graphs where each graph corresponds to a superpixel. Every node in each graph has\n",
    "    as label the grayscale pixel intensity value in the range [0,255]. Each node is connected with at-most 8 neighboors. \n",
    "    \n",
    "    :param image: Image of type 'np.array' having all 3 channels (RGB format).\n",
    "    :param superpixels: The superpixel regions of type 'np.array'.\n",
    "    :return image_graphs: A `list` with graphs for each superpixel. Each graph is an instance of the class\n",
    "    `Graph` within the Grakel library. \n",
    "    \"\"\"\n",
    "    num_of_superpixels = len(np.unique(superpixels)) # The number of superpixels-graphs \n",
    "    image_graphs = []\n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixels == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        adj_matrix = np.zeros((len(indices), len(indices)))  # Adjacency matrix\n",
    "        node_labels = {}  # Dictionary with labels for each vertex.\n",
    "        examined_vertices = []\n",
    "        vertex_index = 0\n",
    "        for vector in indices:\n",
    "            x_coordinate       = vector[0]\n",
    "            y_coordinate       = vector[1]\n",
    "            image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            pixel_intensity    = image_gray[x_coordinate,y_coordinate]\n",
    "            # Update dictionary with attributes for each vertex\n",
    "            node_labels[vertex_index] = pixel_intensity\n",
    "            if examined_vertices == []:  # This is the first vertex to be added\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "            else:\n",
    "                # Update adjacency matrix\n",
    "                for index, existing_vertex in enumerate(examined_vertices):\n",
    "                    if Euclidean_distance(existing_vertex, vector) < 1.45:  # Use a 8-neighbourhood\n",
    "                        adj_matrix[index, vertex_index] = 1\n",
    "                        adj_matrix[vertex_index, index] = 1\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "        G = Graph(adj_matrix, node_labels=node_labels)\n",
    "        image_graphs.append(G)\n",
    "    return image_graphs\n",
    "\n",
    "\n",
    "def create_graphs_edges(image: np.array, superpixels: np.array)->list:\n",
    "    \"\"\"\n",
    "    Create a list of Graphs where each graph corresponds to a superpixel. Every graph has\n",
    "    edge weights which correspond to concatinations of pixel intensity values. \n",
    "    Each node is connected with at-most 8 neighboors. \n",
    "    \n",
    "    :param image: Image of type 'np.array' having all 3 channels (RGB format).\n",
    "    :param superpixels: The superpixel regions of type 'np.array'.\n",
    "    :return image_graphs: A `list` with graphs for each superpixel. \n",
    "    \"\"\"\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate Otsu's threshold\n",
    "    threshold, _ = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    num_of_superpixels = len(np.unique(superpixels)) # The number of superpixels-graphs \n",
    "    image_graphs = []\n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixels == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        adj_matrix = np.zeros((len(indices), len(indices)))  # Adjacency matrix\n",
    "        node_attributes = {}  # Dictionary with attributes for each vertex.\n",
    "        edges = {}\n",
    "        edge_labels = {}\n",
    "        examined_vertices = []\n",
    "        vertex_index = 0\n",
    "        for vector in indices:\n",
    "            x_coordinate       = vector[0]\n",
    "            y_coordinate       = vector[1]\n",
    "            redChannel_value   = image[x_coordinate,y_coordinate,0] # Red channel pixel value \n",
    "            greenChannel_value = image[x_coordinate,y_coordinate,1] # Green channel pixel value\n",
    "            blueChannel_value  = image[x_coordinate,y_coordinate,2] # Blue channel pixel value\n",
    "            \n",
    "                        \n",
    "            # Update dictionary with attributes for each vertex\n",
    "            node_attributes[vertex_index] = [redChannel_value, greenChannel_value, blueChannel_value]\n",
    "            if examined_vertices == []:  # This is the first vertex to be added\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "            else:\n",
    "                # Update adjacency matrix\n",
    "                for index, existing_vertex in enumerate(examined_vertices):\n",
    "                    if Euclidean_distance(existing_vertex, vector) < 1.45:  # Use a 8-neighbourhood\n",
    "                        RGB_1 = node_attributes[index]\n",
    "                        RGB_2 = node_attributes[vertex_index]\n",
    "                        adj_matrix[index, vertex_index] = 1\n",
    "                        adj_matrix[vertex_index, index] = 1\n",
    "                        edges[(index, vertex_index)] = 1\n",
    "                        edges[(vertex_index, index)] = 1\n",
    "                        edge_labels[(index, vertex_index)] = edge_labels_calc(RGB_1, RGB_2)\n",
    "                        edge_labels[(vertex_index, index)] = edge_labels_calc(RGB_1, RGB_2)\n",
    "                examined_vertices.append(vector)\n",
    "                vertex_index = vertex_index + 1\n",
    "        G = Graph(edges, edge_labels=edge_labels)\n",
    "        image_graphs.append(G)\n",
    "    return image_graphs\n",
    "\n",
    "\n",
    "def convert_seg_to_boundaries(seg:np.array)->np.array:\n",
    "    \"\"\" Convert segmentation which uses a different number for each segment into boundries which is \n",
    "        a numpy array that contains 1 for boundry pixels. \n",
    "    \n",
    "    :param seg: The segmentation in region format of type 'np.array'.\n",
    "    :return result: The segmentation in boundry format of type `np.array`.\n",
    "    \"\"\"\n",
    "    seg_padded = np.pad(seg, ((1, 0), (1, 0)), mode='constant', constant_values=seg[-1, -1])\n",
    "    \n",
    "    dx = cv2.Sobel(seg_padded, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    dy = cv2.Sobel(seg_padded, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    boundaries = np.abs(dx) + np.abs(dy)\n",
    "    \n",
    "    boundaries = boundaries[:-1, :-1]\n",
    "    boundaries = cv2.threshold(boundaries, 0, 1, cv2.THRESH_BINARY)[1]\n",
    "    result = boundaries.astype(np.uint8)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def evaluate(Predictions: np.array, Human: np.array)->float:\n",
    "    \"\"\" Calculate the F1-score between the predicted boundries and the ground truth. \n",
    "    \n",
    "    :param Predictions: The predicted boundries of type `np.array`.\n",
    "    :param Human: The human labelled boundries of type `np.array`.\n",
    "    :return f1score: F1 score which takes values between 0 and 1. Value is rounded to 4 decimal points and the \n",
    "    closer the value to 1 the better.\n",
    "    \"\"\"\n",
    "    \n",
    "    TP = Predictions * Human\n",
    "    numFP = 0\n",
    "    numFN = 0\n",
    "    nrow, ncol = Predictions.shape\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            if (Predictions[i,j] == 1) & (Human[i,j]==0):\n",
    "                numFP = numFP + 1\n",
    "            if (Predictions[i,j] == 0) & (Human[i,j]==1): \n",
    "                numFN = numFN + 1\n",
    "    numTP = np.sum(TP)\n",
    "    f1score = 2 * numTP / (2 * numTP + numFP + numFN)\n",
    "\n",
    "    return round(f1score, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7125e",
   "metadata": {},
   "source": [
    "# Data Transformation - Convert Images to Graphs with RGB Node Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Create a list with all the paths for the images in the validation set #\n",
    "#########################################################################\n",
    "\n",
    "folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/val\"  \n",
    "# Construct the pattern to match image files\n",
    "image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "# Use glob to find all matching image file paths\n",
    "image_paths = glob.glob(image_pattern)\n",
    "train_paths = []\n",
    "\n",
    "# Print the paths for each image\n",
    "for path in image_paths:\n",
    "    updated_string = path.rsplit(\"\\\\\", 1)\n",
    "    updated_string = \"/\".join(updated_string)\n",
    "    train_paths.append(updated_string)\n",
    "    \n",
    "#################################################################################\n",
    "# Create a list of lists containing graphs for each image in the validation set #\n",
    "#################################################################################\n",
    "\n",
    "images_to_graphs = []\n",
    "original_images = []\n",
    "superpixel_segmentations = []\n",
    "for path in train_paths[:num_images]:  \n",
    "    current_image = load_image(path)\n",
    "    original_images.append(current_image)\n",
    "    segments = superpixel_SLIC(current_image, 800, 10)\n",
    "    superpixel_segmentations.append(segments)\n",
    "    graphs = create_graphs(current_image, segments)\n",
    "    images_to_graphs.append(graphs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d495231",
   "metadata": {},
   "source": [
    "## Load Ground Truth Segmentations of Τest Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d739064",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                      Load Ground Truth Segmentations                        #\n",
    "###############################################################################\n",
    "# Get dictionary of ground-truth-segmentations\n",
    "ground_truth_segmentations = load_ground_truth_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53ba01",
   "metadata": {},
   "source": [
    "# Plot Superpixels for first 5 Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71187fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 2, 2*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 2, 2*i+2)\n",
    "    plt.imshow(mark_boundaries(image, superpixel_segmentations[i]))\n",
    "    plt.axis('off')\n",
    "    plt.title('Superpixels', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbff593",
   "metadata": {},
   "source": [
    "# Calculate Basic Statistics for Graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1035eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "##### Number of Nodes for Each graph in each Image      #######\n",
    "###############################################################\n",
    "node_counts = []\n",
    "for image in images_to_graphs:\n",
    "    count_nodes = []\n",
    "    for graph in image:\n",
    "        num_nodes = graph.get_adjacency_matrix().shape[0]\n",
    "        count_nodes.append(num_nodes)\n",
    "    node_counts.append(count_nodes)\n",
    "\n",
    "node_counts_freq = node_counts.copy()  # Create a node frequency \n",
    "\n",
    "# Calculate the proportion of the image that each graph covers.\n",
    "for index, path in enumerate(train_paths[:len(node_counts)]):\n",
    "    current_image = load_image(path)\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    total_vertices = n_row*n_col  # All images have the same number of pixels = 154401\n",
    "    node_counts_freq[index] = list(map(lambda x: round((x / total_vertices)*100,2), node_counts[index]))\n",
    "    \n",
    "\n",
    "###############################################################\n",
    "##### Number of Edges for Each graph in each Image      #######\n",
    "###############################################################\n",
    "edge_counts = []\n",
    "for image in images_to_graphs:\n",
    "    count_edges = []\n",
    "    for graph in image:\n",
    "        num_edges = graph.get_adjacency_matrix()\n",
    "        num_edges = np.sum(num_edges == 1)/2\n",
    "        count_edges.append(num_edges)\n",
    "    edge_counts.append(count_edges)\n",
    "\n",
    "# Calculate density for each graph \n",
    "graph_density = []  # Α list of lists where each inside list has the density for each subgraph\n",
    "for i, image in enumerate(edge_counts):\n",
    "    temp_density = []\n",
    "    for j, graph in enumerate(image):\n",
    "        n = node_counts[i][j]\n",
    "        n = n * (n - 1) / 2\n",
    "        density = round((graph/n)*100,2)\n",
    "        temp_density.append(density)\n",
    "    graph_density.append(temp_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe204bd6",
   "metadata": {},
   "source": [
    "# Average Density of Each Graph of Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df898bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "############# Plot Average Graph Density or Each Image    #####\n",
    "###############################################################    \n",
    "\n",
    "# Create box plot for graph densities\n",
    "sns.set(style='ticks', context='paper')\n",
    "sns.histplot(data=[sum(sublist) / len(sublist) for sublist in graph_density])\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Average Graph Density\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Average Density of Graphs for each Image\")\n",
    "\n",
    "# Adjust the plot layout for better presentation\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a14294",
   "metadata": {},
   "source": [
    "# Average Graph size for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "############# Plot Average Graph size for Each Image     ###############\n",
    "#########################################################################\n",
    "\n",
    "# Create box plot for graph sizes \n",
    "sns.set(style='ticks', context='paper')\n",
    "sns.histplot(data=[sum(sublist) / len(sublist) for sublist in node_counts])\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Average Graph Size\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Average Size of Graphs for each Image\")\n",
    "\n",
    "# Adjust the plot layout for better presentation\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e478687",
   "metadata": {},
   "source": [
    "# Average Edge Number for Each Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac721c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "############# Plot Average Edge Number for Each Image     ###############\n",
    "#########################################################################\n",
    "\n",
    "# Create box plot for graph sizes \n",
    "sns.set(style='ticks', context='paper')\n",
    "sns.histplot(data=[sum(sublist) / len(sublist) for sublist in edge_counts])\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Average Edge Number\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Average Edge Number of Graphs for each Image\")\n",
    "\n",
    "# Adjust the plot layout for better presentation\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f37b3d",
   "metadata": {},
   "source": [
    "## Scatterplot of Avg Graph Size vs Avg Graph Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dbd996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bigger the graphs the more sparse they are.\n",
    "# This is due to the fact that a pixel can have atmost 8 neighbours \n",
    "\n",
    "avg_size = [sum(sublist) / len(sublist) for sublist in node_counts]\n",
    "avg_density = [sum(sublist) / len(sublist) for sublist in graph_density]\n",
    "\n",
    "sns.scatterplot(x=avg_size, y=avg_density)\n",
    "plt.xlabel(\"Average Graph Size\")\n",
    "plt.ylabel(\"Average Graph Density\")\n",
    "plt.title(\"Scatterplot of Avg Graph Size vs Avg Graph Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d40f7",
   "metadata": {},
   "source": [
    "# Calculate Kernel Matrix Using Propagation Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ea600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the propagation kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = PropagationAttr(normalize=True,  t_max=2, w=0.001)\n",
    "Kernel_matrix = []\n",
    "for image in images_to_graphs:\n",
    "    current_matrix = gk.fit_transform(image)\n",
    "    # Convert kernel matrix to dissimilarity matrix \n",
    "    current_matrix = 1 - current_matrix\n",
    "    Kernel_matrix.append(current_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a41ba1",
   "metadata": {},
   "source": [
    "# Perform Clustering Using Propagation Kernel Matrices and Hierrarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "    # Perform hierarchical clustering with group average\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "    labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "    predicted_clusters.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e42793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the cluster labels to pixel labels\n",
    "# Each graph in images_to_graphs is assigned a cluster. However each graph is also connected to \n",
    "# several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "    num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        for pixel in indices:\n",
    "            x = pixel[0]\n",
    "            y = pixel[1]\n",
    "            image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "    \n",
    "    image_segmentations.append(image_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d0886b",
   "metadata": {},
   "source": [
    "## Plot Results for first 5 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    \n",
    "    # Get the truth also \n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    human        = ground_truth_segmentations[Image_number][0]\n",
    "    human        = color.label2rgb(human, image, kind='avg', bg_label=0)\n",
    "    \n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 3, 3*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 3, 3*i+2)\n",
    "    # Replace each region with Average RGB values\n",
    "    colored_segmentation =color.label2rgb(image_segmentations[i], image, kind='avg', bg_label=0)\n",
    "    plt.imshow(colored_segmentation)\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "    \n",
    "    # Plot the truth \n",
    "    plt.subplot(5, 3, 3*i+3)\n",
    "    # Replace each region with Average RGB values\n",
    "    plt.imshow(human)\n",
    "    plt.axis('off')\n",
    "    plt.title('True Segmentation', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe9366",
   "metadata": {},
   "source": [
    "# Performance Evaluation - Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988142a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_scores = []\n",
    "propagation_segmentations = image_segmentations.copy()\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    ground_truth               = ground_truth_segmentations[Image_number]\n",
    "    # Get chosen ground truth-segmentation\n",
    "    ground_truth               = ground_truth[0]\n",
    "\n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "    F1_scores.append(F_score)\n",
    "    \n",
    "# Specify the file path and name\n",
    "csv_file = 'Propagation_test_set.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F1_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "F1_scores_propagation = F1_scores.copy()\n",
    "\n",
    "# Save the list as a pickle file\n",
    "with open('propagation_test_results.pkl', 'wb') as file:\n",
    "    pickle.dump(F1_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136ac3a",
   "metadata": {},
   "source": [
    "# Repeat for WL Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2ac2f",
   "metadata": {},
   "source": [
    "# Data Transformation - Convert Images to Graphs with Node Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Create a list with all the paths for the images in the test set     #\n",
    "#######################################################################\n",
    "\n",
    "folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/val\"  \n",
    "# Construct the pattern to match image files\n",
    "image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "# Use glob to find all matching image file paths\n",
    "image_paths = glob.glob(image_pattern)\n",
    "train_paths = []\n",
    "\n",
    "# Print the paths for each image\n",
    "for path in image_paths:\n",
    "    updated_string = path.rsplit(\"\\\\\", 1)\n",
    "    updated_string = \"/\".join(updated_string)\n",
    "    train_paths.append(updated_string)\n",
    "    \n",
    "###############################################################################\n",
    "# Create a list of lists containing graphs for each image in the test set     #\n",
    "###############################################################################\n",
    "\n",
    "images_to_graphs = []\n",
    "original_images = []\n",
    "superpixel_segmentations = []\n",
    "for path in train_paths[:num_images]:  \n",
    "    current_image = load_image(path)\n",
    "    original_images.append(current_image)\n",
    "    segments = superpixel_SLIC(current_image, 800, 10)\n",
    "    superpixel_segmentations.append(segments)\n",
    "    graphs = create_graphs_grayscale(current_image, segments)\n",
    "    images_to_graphs.append(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce877b6",
   "metadata": {},
   "source": [
    "# Calculate Kernel Matrix Using WeisfeilerLehman Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f35a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the WL kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = WeisfeilerLehman(normalize=False, n_iter=4)\n",
    "Kernel_matrix = []\n",
    "for image in images_to_graphs:\n",
    "    current_matrix = gk.fit_transform(image)\n",
    "    # Convert kernel matrix to dissimilarity matrix \n",
    "    current_matrix =  np.max(current_matrix) - current_matrix\n",
    "    Kernel_matrix.append(current_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdfc769",
   "metadata": {},
   "source": [
    "# Perform Clustering Using WL Kernel Matrices and Hierrarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "    # Perform hierarchical clustering with group average\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "    labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "    predicted_clusters.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e415b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the cluster labels to pixel labels\n",
    "# Each graph in images_to_graphs is assigned a cluster. However each graph is also connected to \n",
    "# several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "    num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        for pixel in indices:\n",
    "            x = pixel[0]\n",
    "            y = pixel[1]\n",
    "            image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "    \n",
    "    image_segmentations.append(image_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bc697",
   "metadata": {},
   "source": [
    "## Plot Results for first 5 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    \n",
    "    # Get the truth also \n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    human        = ground_truth_segmentations[Image_number][0]\n",
    "    human        = color.label2rgb(human, image, kind='avg', bg_label=0)\n",
    "    \n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 3, 3*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 3, 3*i+2)\n",
    "    # Replace each region with Average RGB values\n",
    "    colored_segmentation =color.label2rgb(image_segmentations[i], image, kind='avg', bg_label=0)\n",
    "    plt.imshow(colored_segmentation)\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "    \n",
    "    # Plot the truth \n",
    "    plt.subplot(5, 3, 3*i+3)\n",
    "    # Replace each region with Average RGB values\n",
    "    plt.imshow(human)\n",
    "    plt.axis('off')\n",
    "    plt.title('True Segmentation', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b6662",
   "metadata": {},
   "source": [
    "# Performance Evaluation - WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb40cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_scores = []\n",
    "WL_segmentations = image_segmentations.copy()\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    ground_truth               = ground_truth_segmentations[Image_number]\n",
    "    # Get chosen ground truth-segmentation\n",
    "    ground_truth               = ground_truth[0]\n",
    "\n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "    F1_scores.append(F_score)\n",
    "    \n",
    "# Specify the file path and name\n",
    "csv_file = 'WL_test_set.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F1_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "F1_scores_WL = F1_scores.copy()\n",
    "\n",
    "# Save the list as a pickle file\n",
    "with open('WL_test_results.pkl', 'wb') as file:\n",
    "    pickle.dump(F1_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933627c",
   "metadata": {},
   "source": [
    "# Repeat for Shortest Path Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62895b69",
   "metadata": {},
   "source": [
    "# Calculate Kernel Matrix Using Shortest Path Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the SP kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = ShortestPath(normalize=False)\n",
    "Kernel_matrix = []\n",
    "for image in images_to_graphs:\n",
    "    current_matrix = gk.fit_transform(image)\n",
    "    # Convert kernel matrix to distance matrix \n",
    "    current_matrix =  np.max(current_matrix) - current_matrix\n",
    "    Kernel_matrix.append(current_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5a1b8",
   "metadata": {},
   "source": [
    "# Perform Clustering Using Shortest Path Kernel Matrices and Hierrarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "    # Perform hierarchical clustering with group average\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "    labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "    predicted_clusters.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96da54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the cluster labels to pixel labels\n",
    "# Each graph in images_to_graphs[0] is assigned a cluster. However each graph is also connected to \n",
    "# several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "    num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        for pixel in indices:\n",
    "            x = pixel[0]\n",
    "            y = pixel[1]\n",
    "            image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "    \n",
    "    image_segmentations.append(image_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e31b6",
   "metadata": {},
   "source": [
    "# Plot Results for first 5 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60533688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    \n",
    "    # Get the truth also \n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    human        = ground_truth_segmentations[Image_number][0]\n",
    "    human        = color.label2rgb(human, image, kind='avg', bg_label=0)\n",
    "    \n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 3, 3*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 3, 3*i+2)\n",
    "    # Replace each region with Average RGB values\n",
    "    colored_segmentation =color.label2rgb(image_segmentations[i], image, kind='avg', bg_label=0)\n",
    "    plt.imshow(colored_segmentation)\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "    \n",
    "    # Plot the truth \n",
    "    plt.subplot(5, 3, 3*i+3)\n",
    "    # Replace each region with Average RGB values\n",
    "    plt.imshow(human)\n",
    "    plt.axis('off')\n",
    "    plt.title('True Segmentation', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d78fe5c",
   "metadata": {},
   "source": [
    "# Performance Evaluation - Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_scores = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    ground_truth               = ground_truth_segmentations[Image_number]\n",
    "    # Get chosen ground truth-segmentation\n",
    "    ground_truth               = ground_truth[0]\n",
    "\n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "    F1_scores.append(F_score)\n",
    "    \n",
    "# Specify the file path and name\n",
    "csv_file = 'SP_test_set.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F1_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "F1_scores_SP = F1_scores.copy()\n",
    "\n",
    "# Save the list as a pickle file\n",
    "with open('SP_test_results.pkl', 'wb') as file:\n",
    "    pickle.dump(F1_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761310b",
   "metadata": {},
   "source": [
    "# Repeat for Vertex Histogram Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd62799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the WL kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = VertexHistogram(normalize=False)\n",
    "Kernel_matrix = []\n",
    "for image in images_to_graphs:\n",
    "    current_matrix = gk.fit_transform(image)\n",
    "    # Convert kernel matrix to dissimilarity matrix \n",
    "    current_matrix =  np.max(current_matrix) - current_matrix\n",
    "    Kernel_matrix.append(current_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760974e2",
   "metadata": {},
   "source": [
    "# Perform Clustering Using Vertex Histogram Kernel Matrices and Hierrarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67468427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "    # Perform hierarchical clustering with group average\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "    labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "    predicted_clusters.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b84c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the cluster labels to pixel labels\n",
    "# Each graph in images_to_graphs is assigned a cluster. However each graph is also connected to \n",
    "# several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "    num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        for pixel in indices:\n",
    "            x = pixel[0]\n",
    "            y = pixel[1]\n",
    "            image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "    \n",
    "    image_segmentations.append(image_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709a8fd",
   "metadata": {},
   "source": [
    "# Plot Results for first 5 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8eaf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    \n",
    "    # Get the truth also \n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    human        = ground_truth_segmentations[Image_number][0]\n",
    "    human        = color.label2rgb(human, image, kind='avg', bg_label=0)\n",
    "    \n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 3, 3*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 3, 3*i+2)\n",
    "    # Replace each region with Average RGB values\n",
    "    colored_segmentation =color.label2rgb(image_segmentations[i], image, kind='avg', bg_label=0)\n",
    "    plt.imshow(colored_segmentation)\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "    \n",
    "    # Plot the truth \n",
    "    plt.subplot(5, 3, 3*i+3)\n",
    "    # Replace each region with Average RGB values\n",
    "    plt.imshow(human)\n",
    "    plt.axis('off')\n",
    "    plt.title('True Segmentation', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e2c51",
   "metadata": {},
   "source": [
    "# Performance Evaluation - Vertex Histogram Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_scores = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    ground_truth               = ground_truth_segmentations[Image_number]\n",
    "    # Get chosen ground truth-segmentation\n",
    "    ground_truth               = ground_truth[0]\n",
    "\n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "    F1_scores.append(F_score)\n",
    "    \n",
    "# Specify the file path and name\n",
    "csv_file = 'vertex_histogram_test_set.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F1_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "F1_scores_vertex = F1_scores.copy()\n",
    "\n",
    "# Save the list as a pickle file\n",
    "with open('vertex_test_results.pkl', 'wb') as file:\n",
    "    pickle.dump(F1_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aaeca0",
   "metadata": {},
   "source": [
    "# Repeat for Edge Histogram Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ad8a4",
   "metadata": {},
   "source": [
    "# Data Transformation - Convert Images to Graphs with Edge Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Create a list with all the paths for the images in the test set     #\n",
    "#######################################################################\n",
    "\n",
    "folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/val\"  \n",
    "# Construct the pattern to match image files\n",
    "image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "# Use glob to find all matching image file paths\n",
    "image_paths = glob.glob(image_pattern)\n",
    "train_paths = []\n",
    "\n",
    "# Print the paths for each image\n",
    "for path in image_paths:\n",
    "    updated_string = path.rsplit(\"\\\\\", 1)\n",
    "    updated_string = \"/\".join(updated_string)\n",
    "    train_paths.append(updated_string)\n",
    "    \n",
    "###############################################################################\n",
    "# Create a list of lists containing graphs for each image in the test set #\n",
    "###############################################################################\n",
    "\n",
    "images_to_graphs = []\n",
    "original_images = []\n",
    "superpixel_segmentations = []\n",
    "for path in train_paths[:num_images]:  \n",
    "    current_image = load_image(path)\n",
    "    original_images.append(current_image)\n",
    "    segments = superpixel_SLIC(current_image, 800, 10)\n",
    "    superpixel_segmentations.append(segments)\n",
    "    graphs = create_graphs_edges(current_image, segments)\n",
    "    images_to_graphs.append(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ce211",
   "metadata": {},
   "source": [
    "# Calculate Kernel Matrix Using Edge Ηistogram Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the Edge histogram kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = EdgeHistogram(normalize=False)\n",
    "Kernel_matrix = []\n",
    "for image in images_to_graphs:\n",
    "    current_matrix = gk.fit_transform(image)\n",
    "    # Convert kernel matrix to distance matrix \n",
    "    current_matrix =  np.max(current_matrix) - current_matrix\n",
    "    Kernel_matrix.append(current_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d15271",
   "metadata": {},
   "source": [
    "# Perform Clustering Using Edge Histogram Kernel Matrices and Hierrarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "    # Perform hierarchical clustering with group average\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "    labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "    predicted_clusters.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the cluster labels to pixel labels\n",
    "# Each graph in images_to_graphs is assigned a cluster. However each graph is also connected to \n",
    "# several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "    num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        for pixel in indices:\n",
    "            x = pixel[0]\n",
    "            y = pixel[1]\n",
    "            image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "    \n",
    "    image_segmentations.append(image_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c9d67",
   "metadata": {},
   "source": [
    "# Plot Results for first 5 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02711338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    \n",
    "    # Get the truth also \n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    human        = ground_truth_segmentations[Image_number][0]\n",
    "    human        = color.label2rgb(human, image, kind='avg', bg_label=0)\n",
    "    \n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 3, 3*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 3, 3*i+2)\n",
    "    # Replace each region with Average RGB values\n",
    "    colored_segmentation =color.label2rgb(image_segmentations[i], image, kind='avg', bg_label=0)\n",
    "    plt.imshow(colored_segmentation)\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "    \n",
    "    # Plot the truth \n",
    "    plt.subplot(5, 3, 3*i+3)\n",
    "    # Replace each region with Average RGB values\n",
    "    plt.imshow(human)\n",
    "    plt.axis('off')\n",
    "    plt.title('True Segmentation', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852e802",
   "metadata": {},
   "source": [
    "# Performance Evaluation - Edge Histogram Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_scores = []\n",
    "edge_segmentations = image_segmentations.copy()\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    ground_truth               = ground_truth_segmentations[Image_number]\n",
    "    # Get chosen ground truth-segmentation\n",
    "    ground_truth               = ground_truth[0]\n",
    "\n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "    F1_scores.append(F_score)\n",
    "    \n",
    "# Specify the file path and name\n",
    "csv_file = 'edge_histogram_test_set.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F1_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "F1_scores_edge = F1_scores.copy()\n",
    "\n",
    "# Save the list as a pickle file\n",
    "with open('edge_test_results.pkl', 'wb') as file:\n",
    "    pickle.dump(F1_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edb9f8",
   "metadata": {},
   "source": [
    "# Compare Results Between Different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa69de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1_scores_propagation\n",
    "# F1_scores_WL\n",
    "# F1_scores_SP\n",
    "# F1_scores_vertex\n",
    "# F1_scores_edge\n",
    "\n",
    "# Load the pickle file with the results\n",
    "with open('propagation_test_results.pkl', 'rb') as file:\n",
    "    F1_scores_propagation = pickle.load(file)\n",
    "\n",
    "# Load the pickle file with the results\n",
    "with open('WL_test_results.pkl', 'rb') as file:\n",
    "    F1_scores_WL = pickle.load(file)\n",
    "    \n",
    "# Load the pickle file with the results\n",
    "with open('SP_test_results.pkl', 'rb') as file:\n",
    "    F1_scores_SP = pickle.load(file)\n",
    "\n",
    "# Load the pickle file with the results\n",
    "with open('vertex_test_results.pkl', 'rb') as file:\n",
    "    F1_scores_vertex = pickle.load(file)\n",
    "    \n",
    "# Load the pickle file with the results\n",
    "with open('edge_test_results.pkl', 'rb') as file:\n",
    "    F1_scores_edge = pickle.load(file)\n",
    "\n",
    "\n",
    "F1_scores = []\n",
    "F1_scores.append(F1_scores_propagation)\n",
    "F1_scores.append(F1_scores_WL)\n",
    "F1_scores.append(F1_scores_SP)\n",
    "F1_scores.append(F1_scores_vertex)\n",
    "F1_scores.append(F1_scores_edge)\n",
    "\n",
    "labels = ['Propagation', 'WL', 'SP', 'Vertex Histogram', 'Edge Histogram']\n",
    "\n",
    "# Increase figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style='ticks', context='paper')\n",
    "# Plot the results\n",
    "ax = sns.boxplot(data=F1_scores)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "plt.title(\"F1 scores for different Graph Kernels\")\n",
    "\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Graph Kernel')\n",
    "plt.ylabel('F1 score')\n",
    "\n",
    "# Calculate the average values\n",
    "averages = [np.mean(category) for category in F1_scores]\n",
    "\n",
    "# Add average value notations to the top of each box plot\n",
    "for i, average in enumerate(averages):\n",
    "    ax.text(i, np.max(F1_scores[i]) + 0.005 , f'Avg: {average:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Although Propagation kernel achieves way better performance it can undeperform in some cases. \n",
    "# Based on what we saw from the hyperparameter tuning, it is sensitive to the choice of the parameters.\n",
    "# On the other hand we see that kernels that utilize node labels are more stable but tend to underperform.\n",
    "# Also we can see that the inclusion of structural information of the graphs does not improve the result in the case \n",
    "# οf node labelled images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f48cd7",
   "metadata": {},
   "source": [
    "# Perform Wilcoxon signed-rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Wilcoxon_signed-rank\n",
    "# Sources used: \n",
    "# https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "# https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/how-to-conduct-the-wilcox-sign-test/#:~:text=The%20next%20step%20of%20the,where%20the%20difference%20is%20zero.\n",
    "\n",
    "# We are going to apply this test to see whether there is a difference in the median values \n",
    "# We are going to compare the median value of the F1 scores using the Propagation algorithm with the median F1 score\n",
    "# of WL kernel.\n",
    "\n",
    "d = [x - y for x, y in zip(F1_scores_propagation, F1_scores_WL)]  \n",
    "res = wilcoxon(d, alternative='greater')\n",
    "res.statistic, res.pvalue\n",
    "\n",
    "# This shows that the null hypothesis that the median of the difference is zero can be rejected at a confidence level of 5% \n",
    "# in favor of the alternative that the median is greater than zero.\n",
    "# Therefore based on the sample of the 100 images we have enough statistical evidence to say that the \n",
    "# Propagation kernel performs better than the WL.\n",
    "# Of course usage of RGB values play an important role in this result as we use more information for measuring the similarity \n",
    "# between pixeils. Also propagation kernel takes advantange of the distance of the RGB values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e1c7e6",
   "metadata": {},
   "source": [
    "## Comparison Plots of Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the y-values in increasing order and get the corresponding sorted indices\n",
    "sorted_indices = sorted(range(len(F1_scores_propagation)), key=lambda k: F1_scores_propagation[k])\n",
    "sorted_propagation = [F1_scores_propagation[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_WL)), key=lambda k: F1_scores_WL[k])\n",
    "sorted_WL = [F1_scores_WL[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_SP)), key=lambda k: F1_scores_SP[k])\n",
    "sorted_SP = [F1_scores_SP[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_vertex)), key=lambda k: F1_scores_vertex[k])\n",
    "sorted_vertex = [F1_scores_vertex[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_edge)), key=lambda k: F1_scores_edge[k])\n",
    "sorted_edge = [F1_scores_edge[i] for i in sorted_indices]\n",
    "\n",
    "\n",
    "# Plot the line plot using seaborn\n",
    "sns.lineplot(x=range(len(F1_scores_propagation))    , y=sorted_propagation, marker='o',  label='Propagation')\n",
    "sns.lineplot(x=range(len(F1_scores_WL))             , y=sorted_WL, marker='x',  label='WL')\n",
    "sns.lineplot(x=range(len(F1_scores_SP))             , y=sorted_SP, marker='s',  label='SP')\n",
    "sns.lineplot(x=range(len(F1_scores_vertex))         , y=sorted_vertex, marker='^',  label='Vertex')\n",
    "sns.lineplot(x=range(len(F1_scores_edge))           , y=sorted_edge, marker='d',  label='Edge')\n",
    "\n",
    "\n",
    "# Place the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title(\"Comparison of performance among different kernels\")\n",
    "plt.xlabel(\"Image Rank\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "#####################################   Barplot #####################################################\n",
    "#####################################################################################################\n",
    "\n",
    "F1_scores_flattened = []\n",
    "for x in  F1_scores:\n",
    "    for y in x:\n",
    "        F1_scores_flattened.append(y)\n",
    "        \n",
    "labels = ['Propagation']*100 +  ['WL']*100 + ['SP']*100 + ['Vertex Histogram']*100 + ['Edge Histogram']*100 \n",
    "\n",
    "# Create a dictionary to map labels to colors\n",
    "color_dict = {'Propagation': 'blue', 'WL': 'green', 'SP': 'orange', 'Vertex Histogram': 'red', 'Edge Histogram': 'black' }\n",
    "\n",
    "# Set the color palette based on the unique labels\n",
    "colors = [color_dict[label] for label in set(labels)]\n",
    "\n",
    "# Binning parameters\n",
    "num_bins = 4\n",
    "\n",
    "# Initialize the histogram dictionary for each label\n",
    "histograms = {label: np.zeros(num_bins) for label in set(labels)}\n",
    "\n",
    "# Calculate the histogram for each label\n",
    "for label in set(labels):\n",
    "    label_scores = [score for score, lbl in zip(F1_scores_flattened, labels) if lbl == label]\n",
    "    histograms[label], _ = np.histogram(label_scores, bins=[0, 0.15, 0.3, 0.45, 0.80])\n",
    "\n",
    "# Plot the grouped histogram\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.8 / len(set(labels))\n",
    "ax.bar(np.arange(num_bins) + 1 * width, histograms['Propagation'], width=width, color=color_dict['Propagation'], label='Propagation')\n",
    "ax.bar(np.arange(num_bins) + 2 * width, histograms['WL'], width=width, color=color_dict['WL'], label='WL')\n",
    "ax.bar(np.arange(num_bins) + 3 * width, histograms['SP'], width=width, color=color_dict['SP'], label='SP')\n",
    "ax.bar(np.arange(num_bins) + 4 * width, histograms['Vertex Histogram'], width=width, color=color_dict['Vertex Histogram'], label='Vertex Histogram')\n",
    "ax.bar(np.arange(num_bins) + 5 * width, histograms['Edge Histogram'], width=width, color=color_dict['Edge Histogram'], label='Edge Histogram')\n",
    "\n",
    "\n",
    " # Set the x-tick labels to display the bin limits\n",
    "bin_edges = np.array([0, 0.15, 0.3, 0.45, 0.80])\n",
    "bin_labels = [f'{bin_edges[i]:.2f}-{bin_edges[i+1]:.2f}' for i in range(num_bins)]\n",
    "plt.xticks(np.arange(num_bins) + width * (len(set(labels)) - 1) / 2, bin_labels, rotation=45)\n",
    "\n",
    "# # Display the legend\n",
    "# Place the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    \n",
    "# # Set labels and title\n",
    "plt.xlabel('F1 Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Comparison of performance among different kernels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1cc14",
   "metadata": {},
   "source": [
    "# Plot 10 top performing for Propagation vs WL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1fbcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_indexes = list(np.argsort(F1_scores_propagation)[-10:])\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "fig, axs = plt.subplots(nrows=len(Best_indexes), ncols=4, figsize=(15, 5*len(Best_indexes)))\n",
    "\n",
    "for i, image_index in enumerate(Best_indexes):\n",
    "    # Load Original Image\n",
    "    image = original_images[image_index]\n",
    "    \n",
    "    # Convert Segmentation into average RGB values \n",
    "    colored_segmentation_propagation =color.label2rgb(propagation_segmentations[image_index], image, kind='avg', bg_label=0)\n",
    "    colored_segmentation_WL =color.label2rgb(WL_segmentations[image_index], image, kind='avg', bg_label=0)\n",
    "\n",
    "    # Convert Ground Truth to average RGB values\n",
    "    Image_number = get_image_number(train_paths[image_index])\n",
    "    human        = ground_truth_segmentations[Image_number][0]\n",
    "    human        = color.label2rgb(human, image, kind='avg', bg_label=0)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot the original image\n",
    "    axs[i, 0].imshow(image)\n",
    "    axs[i, 0].axis('off')\n",
    "    axs[i, 0].set_title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the propagation segmentation image\n",
    "    axs[i, 1].imshow(colored_segmentation_propagation)\n",
    "    axs[i, 1].axis('off')\n",
    "    axs[i, 1].set_title('Propagation Kernel', fontsize=18)\n",
    "    \n",
    "    # Plot the WL segmentation image\n",
    "    axs[i, 2].imshow(colored_segmentation_WL)\n",
    "    axs[i, 2].axis('off')\n",
    "    axs[i, 2].set_title('WL Kernel', fontsize=18)\n",
    "    \n",
    "    # Plot the human segmentation \n",
    "    axs[i, 3].imshow(human)\n",
    "    axs[i, 3].axis('off')\n",
    "    axs[i, 3].set_title('Human', fontsize=18)\n",
    "    \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af2a03",
   "metadata": {},
   "source": [
    "# Combining Graph Kernels - Average of Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845c6ae",
   "metadata": {},
   "source": [
    "# Average of WL - PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c546c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# Create a list with all the paths for the images in the validation set     #\n",
    "#############################################################################\n",
    "\n",
    "folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/val\"  \n",
    "# Construct the pattern to match image files\n",
    "image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "# Use glob to find all matching image file paths\n",
    "image_paths = glob.glob(image_pattern)\n",
    "train_paths = []\n",
    "\n",
    "# Print the paths for each image\n",
    "for path in image_paths:\n",
    "    updated_string = path.rsplit(\"\\\\\", 1)\n",
    "    updated_string = \"/\".join(updated_string)\n",
    "    train_paths.append(updated_string)\n",
    "    \n",
    "#################################################################################\n",
    "# Create a list of lists containing graphs for each image in the validation set #\n",
    "#################################################################################\n",
    "\n",
    "images_to_graphs_attributes = []\n",
    "images_to_graphs_labels = []\n",
    "original_images = []\n",
    "superpixel_segmentations = []\n",
    "for path in train_paths[:num_images]:  \n",
    "    current_image = load_image(path)\n",
    "    original_images.append(current_image)\n",
    "    segments = superpixel_SLIC(current_image, 800, 10)\n",
    "    superpixel_segmentations.append(segments)\n",
    "    graphs = create_graphs(current_image, segments)\n",
    "    graphs2 = create_graphs_grayscale(current_image, segments)\n",
    "    images_to_graphs_attributes.append(graphs)\n",
    "    images_to_graphs_labels.append(graphs2)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                      Load Ground Truth Segmentations                        #\n",
    "###############################################################################\n",
    "ground_truth_segmentations = load_ground_truth_images()\n",
    "\n",
    "\n",
    "# Uses the propagation kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = PropagationAttr(normalize=True,  t_max=2, w=0.001)\n",
    "wl = WeisfeilerLehman(normalize=True, n_iter=4)\n",
    "Kernel_matrix = []\n",
    "for index in range(0,len(images_to_graphs_attributes)):\n",
    "    current_matrix1 = gk.fit_transform(images_to_graphs_attributes[index])\n",
    "    current_matrix2 = wl.fit_transform(images_to_graphs_labels[index])\n",
    "    # Take the average of the 2 kernel matrices\n",
    "    current_matrix = 0.5*current_matrix1 + 0.5*current_matrix2\n",
    "    # Convert kernel matrix to dissimilarity matrix \n",
    "    current_matrix = 1-current_matrix\n",
    "    Kernel_matrix.append(current_matrix)\n",
    "\n",
    "\n",
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "    # Perform hierarchical clustering with group average\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "    labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "    predicted_clusters.append(labels)\n",
    "\n",
    "\n",
    "# We need to convert the cluster labels to pixel labels\n",
    "# Each graph in images_to_graphs is assigned a cluster. However each graph is also connected to \n",
    "# several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "    num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        for pixel in indices:\n",
    "            x = pixel[0]\n",
    "            y = pixel[1]\n",
    "            image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "    \n",
    "    image_segmentations.append(image_segmentation)\n",
    "\n",
    "segmentations_PG_WL = image_segmentations.copy()  # Store the segmentations for visualasation purposes\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 2, 2*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 2, 2*i+2)\n",
    "    plt.imshow(image_segmentations[i])\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "F1_scores = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    ground_truth               = ground_truth_segmentations[Image_number]\n",
    "    # Get chosen ground truth-segmentation\n",
    "    ground_truth               = ground_truth[0]\n",
    "\n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "    F1_scores.append(F_score)\n",
    "    \n",
    "# Specify the file path and name\n",
    "csv_file = 'PG_WL_test_set.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F1_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "F1_scores_PG_WL = F1_scores.copy()\n",
    "\n",
    "# Save the list as a pickle file\n",
    "with open('PG_WL_results.pkl', 'wb') as file:\n",
    "    pickle.dump(F1_scores, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5960b4",
   "metadata": {},
   "source": [
    "# Average of PG - Shortest Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0293ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Create a list with all the paths for the images in the validation set ###\n",
    "###########################################################################\n",
    "\n",
    "folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/val\"  \n",
    "# Construct the pattern to match image files\n",
    "image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "# Use glob to find all matching image file paths\n",
    "image_paths = glob.glob(image_pattern)\n",
    "train_paths = []\n",
    "\n",
    "# Print the paths for each image\n",
    "for path in image_paths:\n",
    "    updated_string = path.rsplit(\"\\\\\", 1)\n",
    "    updated_string = \"/\".join(updated_string)\n",
    "    train_paths.append(updated_string)\n",
    "    \n",
    "#################################################################################\n",
    "# Create a list of lists containing graphs for each image in the validation set #\n",
    "#################################################################################\n",
    "\n",
    "images_to_graphs_attributes = []\n",
    "images_to_graphs_labels = []\n",
    "original_images = []\n",
    "superpixel_segmentations = []\n",
    "for path in train_paths[:num_images]:  \n",
    "    current_image = load_image(path)\n",
    "    original_images.append(current_image)\n",
    "    segments = superpixel_SLIC(current_image, 800, 10)\n",
    "    superpixel_segmentations.append(segments)\n",
    "    graphs = create_graphs(current_image, segments)\n",
    "    graphs2 = create_graphs_grayscale(current_image, segments)\n",
    "    images_to_graphs_attributes.append(graphs)\n",
    "    images_to_graphs_labels.append(graphs2)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                      Load Ground Truth Segmentations                        #\n",
    "###############################################################################\n",
    "# Get dictionary of ground-truth-segmentations\n",
    "ground_truth_segmentations = load_ground_truth_images()\n",
    "\n",
    "\n",
    "# Uses the propagation kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = PropagationAttr(normalize=True,  t_max=2, w=0.001)\n",
    "sp = ShortestPath(normalize=True)\n",
    "Kernel_matrix = []\n",
    "for index in range(0,len(images_to_graphs_attributes)):\n",
    "    current_matrix1 = gk.fit_transform(images_to_graphs_attributes[index])\n",
    "    current_matrix2 = sp.fit_transform(images_to_graphs_labels[index])\n",
    "    current_matrix = 0.5*current_matrix1 + 0.5*current_matrix2\n",
    "    # Convert kernel matrix to dissimilarity matrix \n",
    "    current_matrix = 1-current_matrix\n",
    "    Kernel_matrix.append(current_matrix)\n",
    "\n",
    "\n",
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "    # Perform hierarchical clustering with group average\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "    labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "    predicted_clusters.append(labels)\n",
    "\n",
    "\n",
    "# We need to convert the cluster labels to pixel labels\n",
    "# Each graph in images_to_graphs is assigned a cluster. However each graph is also connected to \n",
    "# several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "    num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        for pixel in indices:\n",
    "            x = pixel[0]\n",
    "            y = pixel[1]\n",
    "            image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "    \n",
    "    image_segmentations.append(image_segmentation)\n",
    "\n",
    "segmentations_PG_SP = image_segmentations.copy()  # Store the segmentations for visualasation purposes\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 2, 2*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 2, 2*i+2)\n",
    "    plt.imshow(image_segmentations[i])\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "F1_scores = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    ground_truth               = ground_truth_segmentations[Image_number]\n",
    "    # Get chosen ground truth-segmentation\n",
    "    ground_truth               = ground_truth[0]\n",
    "\n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "    F1_scores.append(F_score)\n",
    "    \n",
    "# Specify the file path and name\n",
    "csv_file = 'PG_SP_test_set.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F1_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "F1_scores_PG_SP = F1_scores.copy()\n",
    "\n",
    "# Save the list as a pickle file\n",
    "with open('PG_SP_results.pkl', 'wb') as file:\n",
    "    pickle.dump(F1_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce607b8",
   "metadata": {},
   "source": [
    "# Average of PG - Node Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d752fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Create a list with all the paths for the images in the test set     #\n",
    "#######################################################################\n",
    "\n",
    "folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/val\"  \n",
    "# Construct the pattern to match image files\n",
    "image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "# Use glob to find all matching image file paths\n",
    "image_paths = glob.glob(image_pattern)\n",
    "train_paths = []\n",
    "\n",
    "# Print the paths for each image\n",
    "for path in image_paths:\n",
    "    updated_string = path.rsplit(\"\\\\\", 1)\n",
    "    updated_string = \"/\".join(updated_string)\n",
    "    train_paths.append(updated_string)\n",
    "    \n",
    "#################################################################################\n",
    "# Create a list of lists containing graphs for each image in the validation set #\n",
    "#################################################################################\n",
    "\n",
    "images_to_graphs_attributes = []\n",
    "images_to_graphs_labels = []\n",
    "original_images = []\n",
    "superpixel_segmentations = []\n",
    "for path in train_paths[:num_images]:  \n",
    "    current_image = load_image(path)\n",
    "    original_images.append(current_image)\n",
    "    segments = superpixel_SLIC(current_image, 800, 10)\n",
    "    superpixel_segmentations.append(segments)\n",
    "    graphs = create_graphs(current_image, segments)\n",
    "    graphs2 = create_graphs_grayscale(current_image, segments)\n",
    "    images_to_graphs_attributes.append(graphs)\n",
    "    images_to_graphs_labels.append(graphs2)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                      Load Ground Truth Segmentations                        #\n",
    "###############################################################################\n",
    "# Get dictionary of ground-truth-segmentations\n",
    "ground_truth_segmentations = load_ground_truth_images()\n",
    "\n",
    "\n",
    "# Uses the propagation kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = PropagationAttr(normalize=True,  t_max=2, w=0.001)\n",
    "vh = VertexHistogram(normalize=True)\n",
    "Kernel_matrix = []\n",
    "for index in range(0,len(images_to_graphs_attributes)):\n",
    "    current_matrix1 = gk.fit_transform(images_to_graphs_attributes[index])\n",
    "    current_matrix2 = vh.fit_transform(images_to_graphs_labels[index])\n",
    "    current_matrix = 0.5*current_matrix1 + 0.5*current_matrix2\n",
    "    # Convert kernel matrix to dissimilarity matrix \n",
    "    current_matrix = 1-current_matrix\n",
    "    Kernel_matrix.append(current_matrix)\n",
    "\n",
    "\n",
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    k = ground_truth_segmentations[Image_number][1]  # Get the chosen number of regions\n",
    "    # Perform hierarchical clustering with group average\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "    labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "    predicted_clusters.append(labels)\n",
    "\n",
    "\n",
    "# We need to convert the cluster labels to pixel labels\n",
    "# Each graph in images_to_graphs[0] is assigned a cluster. However each graph is also connected to \n",
    "# several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "    num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "    for graph_num in range(1,num_of_superpixels+1):\n",
    "        indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "        for pixel in indices:\n",
    "            x = pixel[0]\n",
    "            y = pixel[1]\n",
    "            image_segmentation[x,y] = predicted_clusters[i][graph_num-1]\n",
    "    \n",
    "    image_segmentations.append(image_segmentation)\n",
    "\n",
    "segmentations_PG_VH = image_segmentations.copy()  # Store the segmentations for visualasation purposes\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "for i, image in enumerate(original_images[0:5]):\n",
    "    # Plot the original image\n",
    "    plt.subplot(5, 2, 2*i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original', fontsize=18)\n",
    "\n",
    "    # Plot the segmented image\n",
    "    plt.subplot(5, 2, 2*i+2)\n",
    "    plt.imshow(image_segmentations[i])\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmented Image', fontsize=18)\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "F1_scores = []\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    ground_truth               = ground_truth_segmentations[Image_number]\n",
    "    # Get chosen ground truth-segmentation\n",
    "    ground_truth               = ground_truth[0]\n",
    "\n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(ground_truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(image_segmentations[i])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    F_score = evaluate(image_segmentation_boundry, ground_truth_boundry)\n",
    "    F1_scores.append(F_score)\n",
    "    \n",
    "# Specify the file path and name\n",
    "csv_file = 'PG_VH_test_set.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write each element of the list as a row in the CSV file\n",
    "    for item in F1_scores:\n",
    "        writer.writerow([item])\n",
    "        \n",
    "F1_scores_PG_VH = F1_scores.copy()\n",
    "\n",
    "# Save the list as a pickle file\n",
    "with open('PG_VH_results.pkl', 'wb') as file:\n",
    "    pickle.dump(F1_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f64c8",
   "metadata": {},
   "source": [
    "# Compare Results Between Propagation Kernel and Combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba23202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1_scores_propagation\n",
    "# F1_scores_PG_WL\n",
    "# F1_scores_PG_SP\n",
    "# F1_scores_PG_VH\n",
    "\n",
    "\n",
    "# Load the pickle file with the results\n",
    "with open('propagation_test_results.pkl', 'rb') as file:\n",
    "    F1_scores_propagation = pickle.load(file)\n",
    "\n",
    "# Load the pickle file with the results\n",
    "with open('PG_WL_results.pkl', 'rb') as file:\n",
    "    F1_scores_PG_WL = pickle.load(file)\n",
    "    \n",
    "\n",
    "# Load the pickle file with the results\n",
    "with open('PG_SP_results.pkl', 'rb') as file:\n",
    "    F1_scores_PG_SP = pickle.load(file)    \n",
    "\n",
    "\n",
    "# Load the pickle file with the results\n",
    "with open('PG_VH_results.pkl', 'rb') as file:\n",
    "    F1_scores_PG_VH = pickle.load(file)    \n",
    "    \n",
    "\n",
    "F1_scores = []\n",
    "F1_scores.append(F1_scores_propagation)\n",
    "F1_scores.append(F1_scores_PG_WL)\n",
    "F1_scores.append(F1_scores_PG_SP)\n",
    "F1_scores.append(F1_scores_PG_VH)\n",
    "\n",
    "\n",
    "labels = ['Propagation', 'Propagation-WL', 'Propagation-Shortest Path', 'Propagation-Vertex Histogram']\n",
    "\n",
    "# Increase figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style='ticks', context='paper')\n",
    "# Plot the results\n",
    "ax = sns.boxplot(data=F1_scores)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "plt.title(\"F1 scores for different Graph Kernels\")\n",
    "\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Graph Kernel')\n",
    "plt.ylabel('F1 score')\n",
    "\n",
    "# Calculate the average values\n",
    "averages = [np.mean(category) for category in F1_scores]\n",
    "\n",
    "# Add average value notations to the top of each box plot\n",
    "for i, average in enumerate(averages):\n",
    "    ax.text(i, np.max(F1_scores[i]) + 0.005 , f'Avg: {average:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Although Propagation kernel achieves way better performance it can undeperform in some cases. \n",
    "# Based on what we saw from the hyperparameter tuning, it is sensitive so the choice of the parameters.\n",
    "# Simple averages of kernels does not seem to further improve the results. However it reduces the interquartile range. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac8bf1",
   "metadata": {},
   "source": [
    "## Comparison Plots of Performance for among PG and averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08823b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the y-values in increasing order and get the corresponding sorted indices\n",
    "sorted_indices = sorted(range(len(F1_scores_propagation)), key=lambda k: F1_scores_propagation[k])\n",
    "sorted_propagation = [F1_scores_propagation[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_PG_WL)), key=lambda k: F1_scores_PG_WL[k])\n",
    "sorted_PG_WL = [F1_scores_PG_WL[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_PG_SP)), key=lambda k: F1_scores_PG_SP[k])\n",
    "sorted_PG_SP = [F1_scores_PG_SP[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_PG_VH)), key=lambda k: F1_scores_PG_VH[k])\n",
    "sorted_PG_VH = [F1_scores_PG_VH[i] for i in sorted_indices]\n",
    "\n",
    "\n",
    "# Plot the line plot using seaborn\n",
    "sns.lineplot(x=range(len(F1_scores_propagation))    , y=sorted_propagation, marker='o',  label='Propagation')\n",
    "sns.lineplot(x=range(len(F1_scores_PG_WL))          , y=sorted_PG_WL                  ,  marker='o',  label='PG-WL')\n",
    "sns.lineplot(x=range(len(F1_scores_PG_SP))          , y=sorted_PG_SP                  ,  marker='o',  label='PG-SP')\n",
    "sns.lineplot(x=range(len(F1_scores_PG_VH))          , y=sorted_PG_VH                  ,  marker='o',  label='PG-VH')\n",
    "\n",
    "\n",
    "\n",
    "# Display the legend\n",
    "# Place the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title(\"Comparison of performance among combinations of kernels\")\n",
    "plt.xlabel(\"Image Rank\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "#####################################   Barplot #####################################################\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Sample data\n",
    "F1_scores_flattened = []\n",
    "for x in  F1_scores:\n",
    "    for y in x:\n",
    "        F1_scores_flattened.append(y)\n",
    "        \n",
    "labels = ['Propagation']*100 +  ['PG-WL']*100 + ['PG-SP']*100 + ['PG-VH']*100 \n",
    "\n",
    "# Create a dictionary to map labels to colors\n",
    "color_dict = {'Propagation': 'blue', 'PG-WL': 'green', 'PG-SP': 'orange', 'PG-VH': 'red'}\n",
    "\n",
    "# Set the color palette based on the unique labels\n",
    "colors = [color_dict[label] for label in set(labels)]\n",
    "\n",
    "# Binning parameters\n",
    "num_bins = 4\n",
    "\n",
    "# Initialize the histogram dictionary for each label\n",
    "histograms = {label: np.zeros(num_bins) for label in set(labels)}\n",
    "\n",
    "# Calculate the histogram for each label\n",
    "for label in set(labels):\n",
    "    label_scores = [score for score, lbl in zip(F1_scores_flattened, labels) if lbl == label]\n",
    "    histograms[label], _ = np.histogram(label_scores, bins=[0, 0.15, 0.3, 0.45, 0.80])\n",
    "\n",
    "# Plot the grouped histogram\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.8 / len(set(labels))\n",
    "ax.bar(np.arange(num_bins) + 1 * width, histograms['Propagation'], width=width, color=color_dict['Propagation'], label='Propagation')\n",
    "ax.bar(np.arange(num_bins) + 2 * width, histograms['PG-WL'], width=width, color=color_dict['PG-WL'], label='PG-WL')\n",
    "ax.bar(np.arange(num_bins) + 3 * width, histograms['PG-SP'], width=width, color=color_dict['PG-SP'], label='PG-SP')\n",
    "ax.bar(np.arange(num_bins) + 4 * width, histograms['PG-VH'], width=width, color=color_dict['PG-VH'], label='PG-VH')\n",
    "\n",
    "\n",
    " # Set the x-tick labels to display the bin limits\n",
    "bin_edges = np.array([0, 0.15, 0.3, 0.45, 0.80])\n",
    "bin_labels = [f'{bin_edges[i]:.2f}-{bin_edges[i+1]:.2f}' for i in range(num_bins)]\n",
    "plt.xticks(np.arange(num_bins) + width * (len(set(labels)) - 1) / 2, bin_labels, rotation=45)\n",
    "\n",
    "# # Display the legend\n",
    "# Place the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    \n",
    "# # Set labels and title\n",
    "plt.xlabel('F1 Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Comparison of performance among combinations of kernels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b945287",
   "metadata": {},
   "source": [
    "# Comparison of Suggested Approach with Ncut Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877a75a",
   "metadata": {},
   "source": [
    "# Define helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7277671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalised_cuts(image: np.array)->np.array:\n",
    "    \"\"\" Apply normalised cuts to image in order to segment it.\n",
    "    Source: https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_ncut.html#sphx-glr-download-auto-examples-segmentation-plot-ncut-py\n",
    "    \n",
    "    :param image: The image to be segmented with RGB values of type `np.array`.\n",
    "    :param segmentations: The segmentation of the image of type `np.array`.\n",
    "    \"\"\"\n",
    "\n",
    "    img     = image\n",
    "    labels1 = segmentation.slic(img, compactness=10, n_segments=800, start_label=1)\n",
    "    g       = graph.rag_mean_color(img, labels1, mode='similarity')\n",
    "    segmentations = graph.cut_normalized(labels1, g, thresh=0.01)\n",
    "    return segmentations\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "#                      Load ALL Ground Truth Segmentations                    #\n",
    "###############################################################################\n",
    "# Get dictionary of ground-truth-segmentations\n",
    "def load_all_ground_truth_images()->dict:\n",
    "    \"\"\" Create a dictionary with groundtruth segmentations for each image in the training set.\n",
    "    \n",
    "    :return groundtruth: Dictionary of the form key:[segmentation1,segmentation2,...,segmentationk]. For each image\n",
    "    we might have more than 1 ground truth segmentations.\n",
    "    \"\"\"\n",
    "    \n",
    "    folder_path = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/groundTruth/val\"  \n",
    "    # Construct the pattern to match image files\n",
    "    image_pattern = os.path.join(folder_path, '*.mat')  \n",
    "    # Use glob to find all matching image file paths\n",
    "    image_paths = glob.glob(image_pattern)\n",
    "    train_paths = []\n",
    "    groundtruth = {}\n",
    "    # Replace \\ with /\n",
    "    for path in image_paths:\n",
    "        updated_string = path.rsplit(\"\\\\\", 1)\n",
    "        updated_string = \"/\".join(updated_string)\n",
    "        train_paths.append(updated_string)\n",
    "\n",
    "    for path in image_paths:\n",
    "        mat_path = path\n",
    "        # Get the file name from the path\n",
    "        file_name = os.path.basename(path)\n",
    "        # Remove the file extension\n",
    "        file_name = os.path.splitext(file_name)[0]\n",
    "        # Extract the number\n",
    "        image_number = file_name.split(\"\\\\\")[-1]\n",
    "        mat_contents = scipy.io.loadmat(mat_path)\n",
    "        num_of_groundtruths = mat_contents['groundTruth'][0].shape[0]\n",
    "        ground_truths = []\n",
    "        for i in range(0,num_of_groundtruths):\n",
    "            selected_truth = mat_contents['groundTruth'][0][i][0][0][0]\n",
    "            # Downsample true segmentation\n",
    "            selected_truth = downsample_image(selected_truth)\n",
    "            ground_truths.append(selected_truth)\n",
    "        groundtruth[image_number] = ground_truths\n",
    "    return groundtruth\n",
    "\n",
    "\n",
    "def original_Images()->dict:\n",
    "    \n",
    "    \"\"\" Create a dictionary of the form key:value where key = image code and value is the image\n",
    "    \n",
    "    \n",
    "    :return original_images: A dictionary of type `dict` of the form image_number:original_image\n",
    "    \"\"\"\n",
    "    \n",
    "    folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/val\"  \n",
    "    # Construct the pattern to match image files\n",
    "    image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "    # Use glob to find all matching image file paths\n",
    "    image_paths = glob.glob(image_pattern)\n",
    "    train_paths = []\n",
    "\n",
    "    # Print the paths for each image\n",
    "    for path in image_paths:\n",
    "        updated_string = path.rsplit(\"\\\\\", 1)\n",
    "        updated_string = \"/\".join(updated_string)\n",
    "        train_paths.append(updated_string)\n",
    "\n",
    "    original_images = {}\n",
    "    for path in train_paths:  \n",
    "        mat_path = path\n",
    "        # Get the file name from the path\n",
    "        file_name = os.path.basename(path)\n",
    "        # Remove the file extension\n",
    "        file_name = os.path.splitext(file_name)[0]\n",
    "        # Extract the number\n",
    "        image_number = file_name.split(\"\\\\\")[-1]\n",
    "        current_image = load_image(path)\n",
    "        original_images[image_number] = current_image\n",
    "    return original_images\n",
    "\n",
    "\n",
    "\n",
    "# Find all segmentations of normalised cuts\n",
    "def segmentations_Ncuts()->dict:\n",
    "    \"\"\" Find all segmentations using normalised cuts algorithms and store the results \n",
    "    in a dictionary of type `dict`. \n",
    "    \n",
    "    :param segmentations_Ncut: A dictionary with the segmentations of Ncut algorithm of the form \n",
    "    image_number:segmentation. \n",
    "    \"\"\"\n",
    "\n",
    "    segmentations_Ncut = {}\n",
    "    for image_code in original_Images_dict.keys():\n",
    "        segmentations_Ncut[image_code] = Normalised_cuts(original_Images_dict[image_code]).astype(np.uint8)\n",
    "        \n",
    "    return segmentations_Ncut\n",
    "\n",
    "\n",
    "def calc_score(predicted:dict, truth:dict)->list:\n",
    "    \"\"\" Measure performance using F1 score between the predicted segmentation and the truth.\n",
    "    \n",
    "    \n",
    "    :param predicted: The predicted segmentations of type `dict` of the form key:value where\n",
    "    key is the image code and value is the predicted segmentation.\n",
    "    :param truth: The true segmentations of type `dict` of the form key:list[segmentations] where\n",
    "    key is the image code and list[segmentations] is a list of all the human generated segmentations.\n",
    "    :return scores: For each image return the maximum F1 score in a `dict` format. The dictionary stores the \n",
    "    information in the form image_number: max_F1_score.\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    image_codes = list(truth.keys())\n",
    "    for code in image_codes:\n",
    "        truths = truth[code]  # List of all the human segmentations\n",
    "        # Chose the truth with least number of segments \n",
    "        chosen_truth = chosen_truths[code][2]\n",
    "        truths = [truths[chosen_truth]]\n",
    "        prediction = predicted[code]\n",
    "        max_score = 0\n",
    "        for human_segmentations in truths:\n",
    "            # Convert segmentations into boundry formats\n",
    "            ground_truth_boundry = convert_seg_to_boundaries(human_segmentations)\n",
    "            image_segmentation_boundry = convert_seg_to_boundaries(prediction)\n",
    "\n",
    "            # Calculate performance measures \n",
    "            score = evaluate(image_segmentation_boundry, ground_truth_boundry)        \n",
    "    \n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "            else:\n",
    "                pass\n",
    "        scores[code] = max_score\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Load the original images \n",
    "original_Images_dict = original_Images()\n",
    "# Load all the ground truths for the original images \n",
    "load_all_ground_truth_images_dict = load_all_ground_truth_images()\n",
    "chosen_truths = load_ground_truth_images()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc0c15",
   "metadata": {},
   "source": [
    "# Νcut Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a651f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "############################## Measure the performance ####################################\n",
    "###########################################################################################\n",
    "\n",
    "# Convert images to boundries\n",
    "\n",
    "# Normalise Cuts Algorithm\n",
    "Ncuts  = segmentations_Ncuts()\n",
    "ARI_scores_Ncuts = calc_score(Ncuts, load_all_ground_truth_images_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb7a37",
   "metadata": {},
   "source": [
    "# Propagation Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bd09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_train = \"C:/Users/giwrg/Desktop/Master/Modules/Thesis/Reading Material & Data/2- Data/Data Used - 500/images/val\"  \n",
    "# Construct the pattern to match image files\n",
    "image_pattern = os.path.join(folder_path_train, '*.jpg')  \n",
    "# Use glob to find all matching image file paths\n",
    "image_paths = glob.glob(image_pattern)\n",
    "train_paths = []\n",
    "\n",
    "# Print the paths for each image\n",
    "for path in image_paths:\n",
    "    updated_string = path.rsplit(\"\\\\\", 1)\n",
    "    updated_string = \"/\".join(updated_string)\n",
    "    train_paths.append(updated_string)\n",
    "    \n",
    "###############################################################################\n",
    "# Create a list of lists containing graphs for each image in the validation set #\n",
    "###############################################################################\n",
    "\n",
    "images_to_graphs = []\n",
    "original_images = []\n",
    "superpixel_segmentations = []\n",
    "for path in train_paths:  \n",
    "    current_image = load_image(path)\n",
    "    original_images.append(current_image)\n",
    "    segments = superpixel_SLIC(current_image, 800, 10)\n",
    "    superpixel_segmentations.append(segments)\n",
    "    graphs = create_graphs(current_image, segments)\n",
    "    images_to_graphs.append(graphs)\n",
    "\n",
    "\n",
    "# Uses the propagation kernel to generate the kernel matrices\n",
    "# For each Image Calculate the Kernel Matrix \n",
    "gk = PropagationAttr(normalize=True,  t_max=2, w=0.001)\n",
    "Kernel_matrix = []\n",
    "for image in images_to_graphs:\n",
    "    current_matrix = gk.fit_transform(image)\n",
    "    # Convert kernel matrix to dissimilarity matrix \n",
    "    current_matrix = 1 - current_matrix\n",
    "    Kernel_matrix.append(current_matrix)\n",
    "\n",
    "# For the number of clusters use the same number of clusters as the ground truth so that the results are comperable\n",
    "# Get the image number which will be used as key for the groundtruth\n",
    "predicted_clusters = {}\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    predicted_clusters[Image_number] = []\n",
    "    list_of_truths = load_all_ground_truth_images_dict[Image_number]\n",
    "    # Keep only the truth with the least number of segmentes\n",
    "    chosen_truth = chosen_truths[Image_number][2]\n",
    "    list_of_truths = [list_of_truths[chosen_truth]]\n",
    "    K_values = []\n",
    "    # Find the number of regions for each human_segmented_image\n",
    "    for element in list_of_truths:\n",
    "        K_values.append(len(np.unique(element)))\n",
    "    for k in K_values:\n",
    "        # Perform hierarchical clustering with group average\n",
    "        clustering = AgglomerativeClustering(n_clusters=k, linkage='average',metric='precomputed')\n",
    "        labels = clustering.fit_predict(Kernel_matrix[i])\n",
    "        predicted_clusters[Image_number].append(labels)\n",
    "\n",
    "# # We need to convert the cluster labels to pixel labels\n",
    "# # Each graph in images_to_graphs is assigned a cluster. However each graph is also connected to \n",
    "# # several pixels. Therefore we need to assign the graph cluster to their pixels.\n",
    "image_segmentations = {}\n",
    "for i in range(0,len(Kernel_matrix)):\n",
    "    current_image = load_image(train_paths[i])\n",
    "    Image_number = get_image_number(train_paths[i])\n",
    "    image_segmentations[Image_number] = []\n",
    "    n_row, n_col, _ = current_image.shape\n",
    "    predictions = predicted_clusters[Image_number]\n",
    "    # Convert graph clustering labels to image segmentation labels\n",
    "    for j in range(0,len(predictions)):\n",
    "        image_segmentation = np.zeros((n_row, n_col))  # Final Segmentation\n",
    "        num_of_superpixels = len(np.unique(superpixel_segmentations[i])) # The number of superpixels-graphs \n",
    "        for graph_num in range(1,num_of_superpixels+1):\n",
    "            indices = np.argwhere(superpixel_segmentations[i] == graph_num)  # Indices of the pixels which are in the specific superpixel\n",
    "            for pixel in indices:\n",
    "                x = pixel[0]\n",
    "                y = pixel[1]\n",
    "                image_segmentation[x,y] = predictions[j][graph_num-1]\n",
    "\n",
    "        image_segmentations[Image_number].append(image_segmentation)\n",
    "        \n",
    "## Find the F1 score score for each image\n",
    "F1_scores = {}\n",
    "truth = load_all_ground_truth_images_dict\n",
    "image_codes = list(truth.keys())\n",
    "predicted = image_segmentations\n",
    "for code in image_codes:\n",
    "    truths = truth[code]  # List of all the human segmentations\n",
    "    # Κeep only the truth with the smallest number of segments\n",
    "    chosen_truth = chosen_truths[code][2]\n",
    "    truths = [truths[chosen_truth]]\n",
    "    prediction = predicted[code]  # List of all predicted segmentations\n",
    "    max_score = 0\n",
    "    for index, human_segmentations in enumerate(truths):        \n",
    "        # Convert segmentations into boundry formats\n",
    "        ground_truth_boundry = convert_seg_to_boundaries(human_segmentations)\n",
    "        image_segmentation_boundry = convert_seg_to_boundaries(prediction[index])\n",
    "\n",
    "        # Calculate performance measures \n",
    "        score = evaluate(image_segmentation_boundry, ground_truth_boundry)   \n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "        else:\n",
    "            pass\n",
    "    F1_scores[code] = max_score\n",
    "    \n",
    "ARI_scores_Suggested_Approach = F1_scores.copy()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7868c9",
   "metadata": {},
   "source": [
    "# K-means clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.thepythoncode.com/article/kmeans-for-image-segmentation-opencv-python\n",
    "\n",
    "def K_means_segmentation(image:np.array, n_clusters: int)->np.array:\n",
    "    \"\"\" Given an image with RGB values perform K-means clustering\n",
    "        with specified number of clusters.  \n",
    "        \n",
    "    :param image: The image to be segmented of type `np.array`.\n",
    "    :param n_clusters: The number of clusters to use in the clustering of type `int`.\n",
    "    :return segmented_image: The segmented image of type `np.array` where each pixel has \n",
    "    an integer value for the segment it belongs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshaping the image into a 2D array with RGB values\n",
    "    image_transformed = image.reshape((-1, 3))\n",
    "\n",
    "    # Create an array of coordinates\n",
    "    coordinates = np.indices(image[:,:,1].shape).reshape(2, -1).T\n",
    "\n",
    "    # Combine the image_transformed and coordinates arrays\n",
    "    data = np.concatenate((image_transformed, coordinates), axis=1)\n",
    "\n",
    "    # Convert to float type\n",
    "    data = np.float32(data)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85) # Stopping criteria\n",
    "    # Apply K-means 10 times\n",
    "    retval, labels, centers = cv2.kmeans(data, 3, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) \n",
    "    segmented_image = labels.reshape(image[:,:,1].shape) # reshape data into the original image dimensions\n",
    "    \n",
    "    return segmented_image\n",
    "  \n",
    "# Load Original Images\n",
    "original_Images_dict = original_Images()\n",
    "# Load Ground truth Images\n",
    "chosen_truths = load_ground_truth_images()\n",
    "\n",
    "###########################################    \n",
    "# Perform image segmentation using k-means \n",
    "###########################################\n",
    "\n",
    "segmentations_Kmeans = {}\n",
    "F1_scores_Kmeans = []\n",
    "for image_code in original_Images_dict.keys():\n",
    "    current_image = original_Images_dict[image_code]  # Get the current image\n",
    "    num_segments  = chosen_truths[image_code][1]  # Get the number of segments\n",
    "    truth = chosen_truths[image_code][0]  # Get the human segmented truth\n",
    "    segmentations_Kmeans[image_code] = K_means_segmentation(current_image,num_segments).astype(np.uint8)\n",
    "    \n",
    "    # Performance evaluation \n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(segmentations_Kmeans[image_code])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    score = evaluate(image_segmentation_boundry, ground_truth_boundry)   \n",
    "    F1_scores_Kmeans.append(score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df38a8",
   "metadata": {},
   "source": [
    "# Canny Edge Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Canny_detector(image: np.array)->np.array:\n",
    "    \"\"\" Perform Canny edge detector on the given image. \n",
    "    \n",
    "    \n",
    "    :param image: The image to be segmented of type `np.array`.\n",
    "    :return edges: The resulted image after applying canny edge detector \n",
    "    \"\"\"\n",
    "    edges = cv2.Canny(image,200,500)\n",
    "    return edges\n",
    "\n",
    "\n",
    "# Load Original Images\n",
    "original_Images_dict = original_Images()\n",
    "# Load Ground truth Images\n",
    "chosen_truths = load_ground_truth_images()\n",
    "\n",
    "##################################################    \n",
    "# Perform edge detection using Canny Edge Detector \n",
    "##################################################\n",
    "\n",
    "edges_Canny = {}\n",
    "F1_scores_Canny = []\n",
    "for image_code in original_Images_dict.keys():\n",
    "    current_image = original_Images_dict[image_code]  # Get the current image\n",
    "    truth = chosen_truths[image_code][0]  # Get the human segmented truth\n",
    "    edges_Canny[image_code] = Canny_detector(current_image)\n",
    "    \n",
    "    # Performance evaluation \n",
    "    # Convert segmentations into boundry formats\n",
    "    ground_truth_boundry = convert_seg_to_boundaries(truth)\n",
    "    image_segmentation_boundry = convert_seg_to_boundaries(edges_Canny[image_code])\n",
    "\n",
    "    # Calculate performance measures \n",
    "    score = evaluate(image_segmentation_boundry, ground_truth_boundry)   \n",
    "    F1_scores_Canny.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00495ebe",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273351e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "##########################  Line Plot   #########################################\n",
    "#################################################################################\n",
    "\n",
    "Suggested_Approach = list(ARI_scores_Suggested_Approach.values())\n",
    "Ncut               = list(ARI_scores_Ncuts.values())\n",
    "\n",
    "\n",
    "\n",
    "# Sort the y-values in increasing order and get the corresponding sorted indices\n",
    "sorted_indices = sorted(range(len(Suggested_Approach)), key=lambda k: Suggested_Approach[k])\n",
    "Suggested_Approach = [Suggested_Approach[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(Ncut)), key=lambda k: Ncut[k])\n",
    "Ncut = [Ncut[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_Kmeans)), key=lambda k: F1_scores_Kmeans[k])\n",
    "Kmeans = [F1_scores_Kmeans[i] for i in sorted_indices]\n",
    "\n",
    "sorted_indices = sorted(range(len(F1_scores_Canny)), key=lambda k: F1_scores_Canny[k])\n",
    "Canny = [F1_scores_Canny[i] for i in sorted_indices]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the line plot using seaborn\n",
    "sns.lineplot(x=range(len(Ncut))                        , y=Ncut, marker='o'  ,  label='Ncut')\n",
    "sns.lineplot(x=range(len(Suggested_Approach))          , y=Suggested_Approach, marker='^',  label='Propagation Kernel')\n",
    "sns.lineplot(x=range(len(Kmeans))                      , y=Kmeans, marker='x',  label='K means')\n",
    "sns.lineplot(x=range(len(Canny))                       , y=Canny , marker='x',  label='Canny')\n",
    "\n",
    "\n",
    "\n",
    "# Display the legend\n",
    "# Place the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title(\"Comparison of performance among different approaches\")\n",
    "plt.xlabel(\"Image Rank\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "#####################################   Barplot #####################################################\n",
    "#####################################################################################################\n",
    "\n",
    "F1_scores_flattened = Suggested_Approach + Ncut + Kmeans + Canny\n",
    "\n",
    "        \n",
    "labels = ['Propagation Kernel']*100 +  ['Ncut']*100 + ['Kmeans']*100 + ['Canny']*100\n",
    "\n",
    "# Create a dictionary to map labels to colors\n",
    "color_dict = {'Propagation Kernel': 'blue', 'Ncut': 'green', 'Kmeans':'red', 'Canny':'orange'}\n",
    "\n",
    "# Set the color palette based on the unique labels\n",
    "colors = [color_dict[label] for label in set(labels)]\n",
    "\n",
    "# Binning parameters\n",
    "num_bins = 4\n",
    "\n",
    "# Initialize the histogram dictionary for each label\n",
    "histograms = {label: np.zeros(num_bins) for label in set(labels)}\n",
    "\n",
    "# Calculate the histogram for each label\n",
    "for label in set(labels):\n",
    "    label_scores = [score for score, lbl in zip(F1_scores_flattened, labels) if lbl == label]\n",
    "    histograms[label], _ = np.histogram(label_scores, bins=[0, 0.15, 0.3, 0.45, 0.80])\n",
    "\n",
    "# Plot the grouped histogram\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.8 / len(set(labels))\n",
    "ax.bar(np.arange(num_bins) + 1 * width, histograms['Propagation Kernel'], width=width, color=color_dict['Propagation Kernel'], label='Propagation Kernel')\n",
    "ax.bar(np.arange(num_bins) + 2 * width, histograms['Ncut']              , width=width, color=color_dict['Ncut'], label='Ncut')\n",
    "ax.bar(np.arange(num_bins) + 3 * width, histograms['Kmeans']            , width=width, color=color_dict['Kmeans'], label='Kmeans')\n",
    "ax.bar(np.arange(num_bins) + 4 * width, histograms['Canny']             , width=width, color=color_dict['Canny'], label='Canny')\n",
    "\n",
    "# Set the x-tick labels to display the bin limits\n",
    "bin_edges = np.array([0, 0.15, 0.3, 0.45, 0.80])\n",
    "bin_labels = [f'{bin_edges[i]:.2f}-{bin_edges[i+1]:.2f}' for i in range(num_bins)]\n",
    "plt.xticks(np.arange(num_bins) + width * (len(set(labels)) - 1) / 2, bin_labels, rotation=45)\n",
    "\n",
    "# # Display the legend\n",
    "# Place the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "# Set labels and title\n",
    "plt.xlabel('F1 Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Comparison of performance among different approaches')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ccf9a2",
   "metadata": {},
   "source": [
    "# Compare results for each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Suggested_Approach = list(ARI_scores_Suggested_Approach.values())\n",
    "Ncut               = list(ARI_scores_Ncuts.values())\n",
    "\n",
    "sum_count_Propagation = 0\n",
    "for i in range(0,len(Suggested_Approach)):\n",
    "    if (Suggested_Approach[i] > Ncut[i]) and (Suggested_Approach[i] > F1_scores_Kmeans[i]) and (Suggested_Approach[i] > F1_scores_Canny[i]):\n",
    "        sum_count_Propagation = sum_count_Propagation + 1\n",
    "\n",
    "        \n",
    "sum_count_Ncut = 0\n",
    "for i in range(0,len(Suggested_Approach)):\n",
    "    if (Suggested_Approach[i] < Ncut[i]) and (Ncut[i] > F1_scores_Kmeans[i]) and (Ncut[i] > F1_scores_Canny[i]):\n",
    "        sum_count_Ncut = sum_count_Ncut + 1        \n",
    "\n",
    "sum_count_Kmean = 0\n",
    "for i in range(0,len(Suggested_Approach)):\n",
    "    if (Suggested_Approach[i] < F1_scores_Kmeans[i]) and (Ncut[i] < F1_scores_Kmeans[i]) and (F1_scores_Kmeans[i] > F1_scores_Canny[i]):\n",
    "        sum_count_Kmean = sum_count_Kmean + 1     \n",
    "        \n",
    "        \n",
    "sum_count_Canny = 0\n",
    "for i in range(0,len(Suggested_Approach)):\n",
    "    if (Suggested_Approach[i] < F1_scores_Canny[i]) and (Ncut[i] < F1_scores_Canny[i]) and (F1_scores_Kmeans[i] < F1_scores_Canny[i]):\n",
    "        sum_count_Canny = sum_count_Canny + 1   \n",
    "        \n",
    "        \n",
    "print('Propagation Kernel produces better results in: ', sum_count_Propagation)\n",
    "print('Ncut produces better results in: '              , sum_count_Ncut)\n",
    "print('Kmeans produces better results in: '            , sum_count_Kmean)\n",
    "print('Canny produces better results in: '             , sum_count_Canny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedceda9",
   "metadata": {},
   "source": [
    "# Create Comparison Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c67bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get segmentations \n",
    "segmentations_Canny   = list(edges_Canny.values())\n",
    "segmentations_Kmeans_ = list(segmentations_Kmeans.values())\n",
    "segmentations_Ncut    = list(Ncuts.values())\n",
    "\n",
    "# Find indeces where suggested Method Performs best \n",
    "Best_indexes = list(np.argsort(F1_scores_propagation)[-10:])\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create comparison plots for the images\n",
    "fig, axs = plt.subplots(nrows=len(Best_indexes), ncols=6, figsize=(15, 5*len(Best_indexes)))\n",
    "\n",
    "for i, image_index in enumerate(Best_indexes):\n",
    "    # Load Original Image\n",
    "    image = original_images[image_index]\n",
    "    \n",
    "    \n",
    "    # Boundries \n",
    "    colored_segmentation_propagation = convert_seg_to_boundaries(propagation_segmentations[image_index])\n",
    "    colored_segmentation_Ncut        = convert_seg_to_boundaries(segmentations_Ncut[image_index])\n",
    "    colored_segmentation_Kmeans      = convert_seg_to_boundaries(segmentations_Kmeans_[image_index])\n",
    "    colored_segmentation_Canny       = convert_seg_to_boundaries(segmentations_Canny[image_index])\n",
    "    \n",
    "    # Coloured Segmentations\n",
    "#     colored_segmentation_propagation =color.label2rgb(propagation_segmentations[image_index], image, kind='avg', bg_label=0)\n",
    "#     colored_segmentation_Ncut        =color.label2rgb(segmentations_Ncut[image_index]       , image, kind='avg', bg_label=0)\n",
    "#     colored_segmentation_Kmeans      =color.label2rgb(segmentations_Kmeans_[image_index]     , image, kind='avg', bg_label=0)\n",
    "#     colored_segmentation_Canny       =color.label2rgb(segmentations_Canny[image_index]       , image, kind='avg', bg_label=0)\n",
    "    \n",
    "    \n",
    "    # Convert Ground Truth to average RGB values\n",
    "    Image_number = get_image_number(train_paths[image_index])\n",
    "    human        = ground_truth_segmentations[Image_number][0]\n",
    "    human        = convert_seg_to_boundaries(human)\n",
    "#     human        = color.label2rgb(human, image, kind='avg', bg_label=0)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot the original image\n",
    "    axs[i, 0].imshow(image)\n",
    "    axs[i, 0].axis('off')\n",
    "    axs[i, 0].set_title('Original', fontsize=18)\n",
    "    \n",
    "    # Plot the human segmentation \n",
    "    axs[i, 1].imshow(human)\n",
    "    axs[i, 1].axis('off')\n",
    "    axs[i, 1].set_title('Human', fontsize=18)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot the propagation segmentation image\n",
    "    axs[i, 2].imshow(colored_segmentation_propagation)\n",
    "    axs[i, 2].axis('off')\n",
    "    axs[i, 2].set_title('Propagation Kernel', fontsize=18)\n",
    "    \n",
    "    # Plot the Ncut segmentation image\n",
    "    axs[i, 3].imshow(colored_segmentation_Ncut)\n",
    "    axs[i, 3].axis('off')\n",
    "    axs[i, 3].set_title('Νcut', fontsize=18)\n",
    "    \n",
    "    # Plot the Kmeans segmentation image\n",
    "    axs[i, 4].imshow(colored_segmentation_Kmeans)\n",
    "    axs[i, 4].axis('off')\n",
    "    axs[i, 4].set_title('Kmeans', fontsize=18)\n",
    "    \n",
    "    \n",
    "    # Plot the Kmeans segmentation image\n",
    "    axs[i, 5].imshow(colored_segmentation_Canny)\n",
    "    axs[i, 5].axis('off')\n",
    "    axs[i, 5].set_title('Canny', fontsize=18)\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c966947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
